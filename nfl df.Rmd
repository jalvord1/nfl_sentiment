---
title: "Top NFL Players"
author: "Julianna Alvord"
date: "11/29/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(rtweet)
library(rvest)
library(magrittr)
library(tidyr)
library(stringr)
library(ggplot2)
library(tidytext)
```

#scraping and creating full 2018 roster
```{r}
# teams
teams <- c("BUF", "MIA", "NE", "NYJ", "DAL", "NYG", "PHI", "WAS", "BAL", "CIN", "CLE", "PIT", "CHI", "DET", "GB",
           "MIN", "HOU", "IND", "JAX", "TEN", "ATL", "CAR", "NO", "TB", "DEN", "KC", "LAC", "OAK", "ARZ", "LAR",
           "SF", "SEA")

tables <- list()
index <- 1
for(i in teams){
  try({
  url <- paste0("https://www.ourlads.com/nfldepthcharts/roster/", i)
  table <- url %>% 
    read_html() %>% 
    html_table(fill = TRUE)
  
  table[[1]]$team <- i

  tables[index] <- table

  index <- index + 1

  })
}
df <- do.call("rbind", tables)

#checking to make sure it works
df_n_teams <- df %>%
  mutate(n = ifelse(Player == "Active Players", 1, 0)) %>%
  group_by(n) %>%
  summarise(teams = sum(n))

#ew- hand coding- want to figure out better way
df_try2 <- df %>%
  mutate(status = ifelse(row.names(df) %in% c(2:54, 71:123, 147:199, 227:279, 298:350, 373:425,
                                              446:498, 522:574, 601:653, 681:733, 757:809, 832:885,
                                              911:963, 983:1034, 1052:1103, 1125:1177, 1200:1252,
                                              1274:1326, 1350:1402, 1428:1480, 1500:1553, 1572:1623,
                                              1646:1698, 1723:1775, 1799:1851, 1874:1926, 1952:2004,
                                              2025:2077, 2103:2155, 2175:2227, 2249:2301, 2322:2374), "active",
                         ifelse(row.names(df) %in% c(56:64, 125:133, 201:210, 281:289, 352:360, 427:435,
                                                     500:509, 576:584, 655:665, 735:745, 811:821, 887:897, 
                                                     965:974, 1036:1045, 1105:1114, 1179:1188, 1254:1263,
                                                     1328:1336, 1404:1413, 1482:1491, 1555:1564, 1625:1634,
                                                     1700:1709, 1777:1787, 1853:1862, 1928:1937, 2006:2015,
                                                     2079:2088, 2157:2166, 2229:2238, 2303:2311, 2376:2385), "practice",
                                "reserve"))) %>%
  filter(!Player %in% c("Active Players", "Practice Squad", "Reserves"))

#how to group by the teams?
#manually?
#can I do a loop if I have two lists?

splits <- str_split_fixed(df_try2$Player, ", ", 2)
df_try2$Name <- paste(splits[,2], splits[,1], sep = ' ')

full_roster <- df_try2 %>%
  select(-Player)

# write.csv(full_roster, "/Volumes/easystore/Special Studies Fall 2018/full_roster_11-29-18.csv")
```

#top 100 scraping
```{r}
#top 100
url<- "https://en.wikipedia.org/wiki/NFL_Top_100_Players_of_2018"

top100 <- url %>%
  read_html() %>%
  html_nodes(xpath = '//*[@id="mw-content-text"]/div/table[3]') %>%
  html_table()

top100 <- top100[[1]]

#bring in race df
race100 <- read.csv("/Volumes/easystore/Special Studies Fall 2018/nfl top 100 race.csv", stringsAsFactors = FALSE)

top100_full <- top100 %>%
  full_join(race100)

#FIXING NAMES FOR JOIN WITH FULL ROSTER

top100_full <- top100_full %>%
  mutate(Name = ifelse(Player == "A. J. Green", "AJ Green",
                       ifelse(Player == "DeMarcus Lawrence", "Demarcus Lawrence",
                              ifelse(Player == "A. J. Bouye", "AJ Bouye",
                                     ifelse(Player == "Mark Ingram Jr.", "Mark Ingram",
                                            ifelse(Player == "J. J. Watt", "JJ Watt",
                                                   ifelse(Player == "Chris Harris Jr.", "Chris Harris",
                                                          ifelse(Player == "C. J. Mosley", "CJ Mosley", Player))))))))


#join with full roster?
full_w_top100 <- full_roster %>%
  full_join(top100_full, by = "Name")

# write.csv(full_w_top100, "/Volumes/easystore/Special Studies Fall 2018/full roster with race.csv")
```

#position by race
```{r}
top100_more <- full_w_top100 %>%
  filter(!is.na(Race)) %>%
  #there are more than 1 michael thomas
  filter(!(Name == "Michael Thomas" & team == "NYG"))

group <- top100_more %>%
  group_by(Race, Position) %>%
  summarise(n = n()) 
  #spread(key = Race, value = n)

ggplot(group, aes(x=Position, y=n, fill=Race)) +
    geom_bar(stat='identity', position='dodge') +
  theme(axis.text.x = element_text(angle = 90))
```

#play by play data
```{r}
#Play by play data
pbp1 <- read.csv("/Volumes/easystore/Special Studies Fall 2018/pbp_11-27-18.csv") 

top100_more <- top100_more %>%
  mutate(nametosplit = Name) %>%
  separate(col = nametosplit, into = c("firstname", "lastname"), sep = "\\ ") %>%
  mutate(lastname = toupper(ifelse(firstname == "Ha", "Clinton-Dix", lastname)),
         firstinitial = substring(firstname, 1, 1),
         #to be able to look them up in play by play data
         firstlast = paste(firstinitial, lastname, sep = "."))
```

#creating column to loop through twitter
```{r}
top100_more$twitter <- top100_more$Twitter[3]

top100_more <- top100_more %>%
  mutate(fortwitter = ifelse(Twitter == "", Player, Twitter))
```

#sourcing cleaning and gathering rmd
```{r}
source("cleaning and gathering data.R")
```


#looping through twitter for tweet data
```{r}
twitter <- top100_more$fortwitter

datalist = list()

# Loop through the twitter handles & store the results as individual dataframes
for(handle in twitter) {
  result <- search_tweets(handle, n = 100, include_rts = FALSE)
  result$Source <- handle
  
  words <- result %>% 
    select(status_id, text) %>% 
    unnest_tokens(word,text)
    
  my_stop_words <- stop_words %>% select(-lexicon) %>% 
  bind_rows(data.frame(word = c("https", "t.co", "rt", "amp","4yig9gzh5t","fyy2ceydhi","78","fakenews")))

  tweet_words <- words %>% anti_join(my_stop_words)
  
  bing_lex <- get_sentiments("nrc")

  fn_sentiment <- tweet_words %>% 
    left_join(bing_lex) 
  
  df <- fn_sentiment %>% filter(!is.na(sentiment)) %>% group_by(sentiment) %>% summarise(n=n())

  df_2 <- df %>%
  mutate(player = handle) %>%
    spread(key = sentiment, value = n)
  
  datalist[[handle]] <- df_2
  
  #creating names
  df_name <- substring(handle, 1)
  
  words_name <- paste(substring(handle, 1), "word", sep = "_")

  if(exists(df_name)) {
    assign(df_name, unique(rbind(get(df_name), result)))
  } else {
    assign(df_name, result)
    
    assign(words_name, df_2)
  }
  Sys.sleep(5)
}

sentiments_full = do.call(rbind, datalist)
```

#combining sentiments with top 100 df
```{r}
full100 <- top100_more %>%
  full_join(sentiments_full, by = c("fortwitter" = "player")) %>%
  mutate(totalsentiment = anger + anticipation + disgust + fear + joy + negative + positive + sadness +
           surprise + trust,
         anger_perc = anger/totalsentiment * 100,
         anticipation_perc = anticipation/totalsentiment *100,
         disgust_perc = disgust/totalsentiment *100,
         fear_perc = fear/totalsentiment *100,
         joy_perc = joy/totalsentiment *100,
         negative_perc = negative/totalsentiment *100,
         positive_perc = positive/totalsentiment *100,
         sadness_perc = sadness/totalsentiment *100,
         surprise_perc = surprise/totalsentiment *100,
         trust_perc = trust/totalsentiment *100)

full100_format <- full100 %>%
  select(Player, Race, 42:51) %>%
  gather(sentiment, n, 3:12)

full100_2 <- full100_format %>%
  dplyr::group_by(sentiment, Race) %>%
  summarise(mean_perc_sent = mean(n))

#analyzing sentiments
ggplot(full100_2, aes(x = sentiment, y = mean_perc_sent, fill = Race)) +
  geom_bar(stat = "identity", position = "dodge", color = "black") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_fill_manual(values=c("black", "white"))
  
```

11/29/18
```{r}
#pull for saints v cowboys 11/29/18

top100_11_29 <- top100_more %>%
  filter(team %in% c("NO", "DAL"))

twitter <- top100_11_29$fortwitter

datalist = list()

# Loop through the twitter handles & store the results as individual dataframes
for(handle in twitter) {
  result <- search_tweets(handle, n = 1000, include_rts = FALSE)
  result$Source <- handle
  
  words <- result %>% 
    select(status_id, text) %>% 
    unnest_tokens(word,text)
    
  my_stop_words <- stop_words %>% select(-lexicon) %>% 
  bind_rows(data.frame(word = c("https", "t.co", "rt", "amp","4yig9gzh5t","fyy2ceydhi","78","fakenews")))

  tweet_words <- words %>% anti_join(my_stop_words)
  
  bing_lex <- get_sentiments("nrc")

  fn_sentiment <- tweet_words %>% 
    left_join(bing_lex) 
  
  df <- fn_sentiment %>% filter(!is.na(sentiment)) %>% group_by(sentiment) %>% summarise(n=n())

  df_2 <- df %>%
  mutate(player = handle) %>%
    spread(key = sentiment, value = n)
  
  datalist[[handle]] <- df_2
  
  #creating names
  df_name <- substring(handle, 1)
  
  words_name <- paste(substring(handle, 1), "word", sep = "_")

  if(exists(df_name)) {
    assign(df_name, unique(rbind(get(df_name), result)))
  } else {
    assign(df_name, result)
    
    assign(words_name, df_2)
  }
  Sys.sleep(5)
}

sentiments_T1 = do.call(rbind, datalist)

#write.csv(sentiments_T1, "/Volumes/easystore/Special Studies Fall 2018/sentiments_t1 saints v dallas 180.csv")
write.csv(sentiments_T1, "/Volumes/easystore/Special Studies Fall 2018/sentiments_t1 saints v dallas 1000.csv")

```

```{r}
full100 <- top100_more %>%
  full_join(sentiments_full, by = c("fortwitter" = "player")) %>%
  mutate(totalsentiment = anger + anticipation + disgust + fear + joy + negative + positive + sadness +
           surprise + trust,
         anger_perc = anger/totalsentiment * 100,
         anticipation_perc = anticipation/totalsentiment *100,
         disgust_perc = disgust/totalsentiment *100,
         fear_perc = fear/totalsentiment *100,
         joy_perc = joy/totalsentiment *100,
         negative_perc = negative/totalsentiment *100,
         positive_perc = positive/totalsentiment *100,
         sadness_perc = sadness/totalsentiment *100,
         surprise_perc = surprise/totalsentiment *100,
         trust_perc = trust/totalsentiment *100)

full100_format <- full100 %>%
  select(Player, Race, 42:51) %>%
  gather(sentiment, n, 3:12)

full100_2 <- full100_format %>%
  dplyr::group_by(sentiment, Race) %>%
  summarise(mean_perc_sent = mean(n))

#analyzing sentiments
ggplot(full100_2, aes(x = sentiment, y = mean_perc_sent, fill = Race)) +
  geom_bar(stat = "identity", position = "dodge", color = "black") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_fill_manual(values=c("black", "white"))
```

#trying loop with 15 min break
```{r}
#pull for gronk and brady

top100_TWO <- top100_more %>%
  filter(lastname %in% c("GRONKOWSKI", "BRADY", "BECKHAM"))

twitter <- top100_TWO$fortwitter

datalist = list()

# Loop through the twitter handles & store the results as individual dataframes
for(handle in twitter) {
  result <- search_tweets(handle, n = 6000, include_rts = FALSE)
  result$Source <- handle
  
  words <- result %>% 
    select(status_id, text) %>% 
    unnest_tokens(word,text)
    
  my_stop_words <- stop_words %>% select(-lexicon) %>% 
  bind_rows(data.frame(word = c("https", "t.co", "rt", "amp","4yig9gzh5t","fyy2ceydhi","78","fakenews")))

  tweet_words <- words %>% anti_join(my_stop_words)
  
  bing_lex <- get_sentiments("nrc")

  fn_sentiment <- tweet_words %>% 
    left_join(bing_lex) 
  
  df <- fn_sentiment %>% filter(!is.na(sentiment)) %>% group_by(sentiment) %>% summarise(n=n())

  df_2 <- df %>%
  mutate(player = handle) %>%
    spread(key = sentiment, value = n)
  
  datalist[[handle]] <- df_2
  
  #creating names
  df_name <- substring(handle, 1)
  
  words_name <- paste(substring(handle, 1), "word", sep = "_")

  if(exists(df_name)) {
    assign(df_name, unique(rbind(get(df_name), result)))
  } else {
    assign(df_name, result)
    
    assign(words_name, df_2)
  }
  Sys.sleep(300)
}

sentiments_T1 = do.call(rbind, datalist)

#write.csv(sentiments_T1, "/Volumes/easystore/Special Studies Fall 2018/sentiments_t1 saints v dallas 180.csv")
#write.csv(sentiments_T1, "/Volumes/easystore/Special Studies Fall 2018/sentiments_t1 saints v dallas 1000.csv")

```
