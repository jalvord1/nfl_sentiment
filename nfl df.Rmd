---
title: "Top NFL Players"
author: "Julianna Alvord"
date: "11/29/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(rtweet)
library(rvest)
library(magrittr)
library(tidyr)
library(stringr)
library(ggplot2)
library(tidytext)
```


#sourcing cleaning and gathering rmd
```{r}
source("cleaning and gathering data.R")
```


#looping through twitter for tweet data
```{r}
twitter <- top100_more$fortwitter

datalist = list()

# Loop through the twitter handles & store the results as individual dataframes
for(handle in twitter) {
  result <- search_tweets(handle, n = 100, include_rts = FALSE)
  result$Source <- handle
  
  words <- result %>% 
    select(status_id, text) %>% 
    unnest_tokens(word,text)
    
  my_stop_words <- stop_words %>% select(-lexicon) %>% 
  bind_rows(data.frame(word = c("https", "t.co", "rt", "amp","4yig9gzh5t","fyy2ceydhi","78","fakenews")))

  tweet_words <- words %>% anti_join(my_stop_words)
  
  bing_lex <- get_sentiments("nrc")

  fn_sentiment <- tweet_words %>% 
    left_join(bing_lex) 
  
  df <- fn_sentiment %>% filter(!is.na(sentiment)) %>% group_by(sentiment) %>% summarise(n=n())

  df_2 <- df %>%
  mutate(player = handle) %>%
    spread(key = sentiment, value = n)
  
  datalist[[handle]] <- df_2
  
  #creating names
  df_name <- substring(handle, 1)
  
  words_name <- paste(substring(handle, 1), "word", sep = "_")

  if(exists(df_name)) {
    assign(df_name, unique(rbind(get(df_name), result)))
  } else {
    assign(df_name, result)
    
    assign(words_name, df_2)
  }
  Sys.sleep(5)
}

sentiments_full = do.call(rbind, datalist)
```

#combining sentiments with top 100 df
```{r}
full100 <- top100_more %>%
  full_join(sentiments_full, by = c("fortwitter" = "player")) %>%
  mutate(totalsentiment = anger + anticipation + disgust + fear + joy + negative + positive + sadness +
           surprise + trust,
         anger_perc = anger/totalsentiment * 100,
         anticipation_perc = anticipation/totalsentiment *100,
         disgust_perc = disgust/totalsentiment *100,
         fear_perc = fear/totalsentiment *100,
         joy_perc = joy/totalsentiment *100,
         negative_perc = negative/totalsentiment *100,
         positive_perc = positive/totalsentiment *100,
         sadness_perc = sadness/totalsentiment *100,
         surprise_perc = surprise/totalsentiment *100,
         trust_perc = trust/totalsentiment *100)

full100_format <- full100 %>%
  select(Player, Race, 42:51) %>%
  gather(sentiment, n, 3:12)

full100_2 <- full100_format %>%
  dplyr::group_by(sentiment, Race) %>%
  summarise(mean_perc_sent = mean(n))

#analyzing sentiments
ggplot(full100_2, aes(x = sentiment, y = mean_perc_sent, fill = Race)) +
  geom_bar(stat = "identity", position = "dodge", color = "black") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_fill_manual(values=c("black", "white"))
  
```

11/29/18
```{r}
#pull for saints v cowboys 11/29/18

top100_11_29 <- top100_more %>%
  filter(team %in% c("NO", "DAL"))

twitter <- top100_11_29$fortwitter

datalist = list()

# Loop through the twitter handles & store the results as individual dataframes
for(handle in twitter) {
  result <- search_tweets(handle, n = 1000, include_rts = FALSE)
  result$Source <- handle
  
  words <- result %>% 
    select(status_id, text) %>% 
    unnest_tokens(word,text)
    
  my_stop_words <- stop_words %>% select(-lexicon) %>% 
  bind_rows(data.frame(word = c("https", "t.co", "rt", "amp","4yig9gzh5t","fyy2ceydhi","78","fakenews")))

  tweet_words <- words %>% anti_join(my_stop_words)
  
  bing_lex <- get_sentiments("nrc")

  fn_sentiment <- tweet_words %>% 
    left_join(bing_lex) 
  
  df <- fn_sentiment %>% filter(!is.na(sentiment)) %>% group_by(sentiment) %>% summarise(n=n())

  df_2 <- df %>%
  mutate(player = handle) %>%
    spread(key = sentiment, value = n)
  
  datalist[[handle]] <- df_2
  
  #creating names
  df_name <- substring(handle, 1)
  
  words_name <- paste(substring(handle, 1), "word", sep = "_")

  if(exists(df_name)) {
    assign(df_name, unique(rbind(get(df_name), result)))
  } else {
    assign(df_name, result)
    
    assign(words_name, df_2)
  }
  Sys.sleep(5)
}

sentiments_T1 = do.call(rbind, datalist)

#write.csv(sentiments_T1, "/Volumes/easystore/Special Studies Fall 2018/sentiments_t1 saints v dallas 180.csv")
write.csv(sentiments_T1, "/Volumes/easystore/Special Studies Fall 2018/sentiments_t1 saints v dallas 1000.csv")

```

```{r}
full100 <- top100_more %>%
  full_join(sentiments_full, by = c("fortwitter" = "player")) %>%
  mutate(totalsentiment = anger + anticipation + disgust + fear + joy + negative + positive + sadness +
           surprise + trust,
         anger_perc = anger/totalsentiment * 100,
         anticipation_perc = anticipation/totalsentiment *100,
         disgust_perc = disgust/totalsentiment *100,
         fear_perc = fear/totalsentiment *100,
         joy_perc = joy/totalsentiment *100,
         negative_perc = negative/totalsentiment *100,
         positive_perc = positive/totalsentiment *100,
         sadness_perc = sadness/totalsentiment *100,
         surprise_perc = surprise/totalsentiment *100,
         trust_perc = trust/totalsentiment *100)

full100_format <- full100 %>%
  select(Player, Race, 42:51) %>%
  gather(sentiment, n, 3:12)

full100_2 <- full100_format %>%
  dplyr::group_by(sentiment, Race) %>%
  summarise(mean_perc_sent = mean(n))

#analyzing sentiments
ggplot(full100_2, aes(x = sentiment, y = mean_perc_sent, fill = Race)) +
  geom_bar(stat = "identity", position = "dodge", color = "black") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_fill_manual(values=c("black", "white"))
```

#trying loop with 15 min break
```{r}
#pull for gronk and brady

top100_TWO <- top100_more %>%
  filter(lastname %in% c("GRONKOWSKI", "BRADY", "BECKHAM"))

twitter <- top100_TWO$fortwitter

datalist = list()

# Loop through the twitter handles & store the results as individual dataframes
for(handle in twitter) {
  result <- search_tweets(handle, n = 6000, include_rts = FALSE)
  result$Source <- handle
  
  words <- result %>% 
    select(status_id, text) %>% 
    unnest_tokens(word,text)
    
  my_stop_words <- stop_words %>% select(-lexicon) %>% 
  bind_rows(data.frame(word = c("https", "t.co", "rt", "amp","4yig9gzh5t","fyy2ceydhi","78","fakenews")))

  tweet_words <- words %>% anti_join(my_stop_words)
  
  bing_lex <- get_sentiments("nrc")

  fn_sentiment <- tweet_words %>% 
    left_join(bing_lex) 
  
  df <- fn_sentiment %>% filter(!is.na(sentiment)) %>% group_by(sentiment) %>% summarise(n=n())

  df_2 <- df %>%
  mutate(player = handle) %>%
    spread(key = sentiment, value = n)
  
  datalist[[handle]] <- df_2
  
  #creating names
  df_name <- substring(handle, 1)
  
  words_name <- paste(substring(handle, 1), "word", sep = "_")

  if(exists(df_name)) {
    assign(df_name, unique(rbind(get(df_name), result)))
  } else {
    assign(df_name, result)
    
    assign(words_name, df_2)
  }
  Sys.sleep(300)
}

sentiments_T1 = do.call(rbind, datalist)

#write.csv(sentiments_T1, "/Volumes/easystore/Special Studies Fall 2018/sentiments_t1 saints v dallas 180.csv")
#write.csv(sentiments_T1, "/Volumes/easystore/Special Studies Fall 2018/sentiments_t1 saints v dallas 1000.csv")

```
