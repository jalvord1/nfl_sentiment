---
title: "Twitter Search NFL"
author: "Julianna Alvord"
date: "1/7/2019"
output: html_document
---

```{r}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(rtweet)
library(rvest)
library(magrittr)
library(tidyr)
library(stringr)
library(ggplot2)
library(tidytext)
library(twitteR)
```

```{r}
source("cleaning and gathering data.R")

consumer_key <- 'xx'
consumer_secret <- 'xx'
access_token <- 'xx'
access_secret <- 'xx'

setup_twitter_oauth(consumer_key, consumer_secret, access_token, access_secret)
```


#trying loop with 1 min break
```{r}
#pull for Thursday September 6
#T1
top100_9_6 <- top100_more %>%
  filter(`2018 team` %in% c("Atlanta Falcons", "Philadelphia Eagles"))

twitter <- top100_9_6$fortwitter

datalist = list()

# Loop through the twitter handles & store the results as individual dataframes
for(handle in twitter) {
  result <- searchTwitter(handle, n = 3000, since = '2018-09-06', until = '2018-09-06')
  
  result$Source <- handle
  
  words <- result %>% 
    select(status_id, text) %>% 
    unnest_tokens(word,text)
    
  my_stop_words <- stop_words %>% select(-lexicon) %>% 
  bind_rows(data.frame(word = c("https", "t.co", "rt", "amp","4yig9gzh5t","fyy2ceydhi","78","fakenews")))

  tweet_words <- words %>% anti_join(my_stop_words)
  
  bing_lex <- get_sentiments("nrc")

  fn_sentiment <- tweet_words %>% 
    left_join(bing_lex) 
  
  df <- fn_sentiment %>% filter(!is.na(sentiment)) %>% group_by(sentiment) %>% summarise(n=n())

  df_2 <- df %>%
  mutate(player = handle) %>%
    spread(key = sentiment, value = n)
  
  datalist[[handle]] <- df_2
  
  #creating names
  df_name <- handle
  
  words_name <- paste(handle, "word", sep = "_")

  if(exists(df_name)) {
    assign(df_name, unique(rbind(get(df_name), result)))
  } else {
    assign(df_name, result)
    
    assign(words_name, df_2)
  }
  Sys.sleep(65)
}

sentiments_T1 = do.call(rbind, datalist)
```