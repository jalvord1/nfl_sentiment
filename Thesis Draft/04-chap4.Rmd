```{r include = FALSE}
library(httr)
library(twitteR)
library(rtweet)
library(dplyr)
library(readr)
library(ggplot2)
library(rvest)
library(magrittr)
library(tidyr)
library(stringr)
library(tidytext)
library(scales)
library(kableExtra)
library(lme4)
library(lavaan)
library(nlme)
library(semPlot)
library(stats)
library(visreg)
library(knitr)
library(reticulate)
```

#Study 2

##Introduction

After gathering the analyzing tweets posted during the Superbowl, we wanted to create a balance study that would allow us to build models to determine if there are significant relationships between race, outcome, and percentage of negative tweets. As previously stated, our research question was: The main research question is as follows: Are sentiments on Twitter more negative towards black NFL players after controlling for game outcome and quality of play? In order to add outcome to this analysis, we are including multiple games as separate time points. 

We have two main hypotheses. First, we hypothesize that during a game that was won, sentiments will be less negative. Second, we hypothesize that during a game that was lost, sentiments will be more negative toward black players. 

##Methods

###Full-Archive Twitter API

In order to gather tweets through Twitter's APIs, three options are available: the standard, 30-day archive, and the full-archive searches. Within the advanced search methods (30-day and full archive), there is a free "sandbox" option to allow researchers to test applications or other functions. The details of these can be found in chapter 1. The chosen method for this project is the premium full-archive search given our desire to focus on games from 2017. This method has strict limits in terms of the number of tweets that can be scraped per month. Below is an image that specifies these limits.

```{r, echo = FALSE, fig.cap="Twitter Full-Archive Search Limits", out.width = "475px"}
include_graphics(path = "api_limits.png", auto_pdf = TRUE)
```

In addition to these limits, there are monthly limits which depend on the level of access that is selected. We chose a 500/month request limit for this project. Therefore, with 500 requests per month and 500 tweets per request, we are capped at 250,000 tweets total. This restraint determined and influenced many decisions of this study, especially in regard to the choice of players to include in our sample. 

###Chosen Games and Sample

Initially, when beginning this project, we hoped to use individual plays of a game as the measurement level. We looked to use play-by-play data that was gathered earlier and match the time of plays to the time of tweets. Included in this dataset were plays from the first six games of the 2017 season. However, due to discrepencies in the time variables and other restraints, this was not possible. Regardless, we are chosing to continue to focus on those specific games. First, we believe that six games allows us enough time points while still giving us the ability to gather enough tweets to accurately measure and model sentiments. Moreover, in 2017, US President Donald Trump attacked NFL players who had chosen to kneel in support of Colin Kaepernick on multiple platforms. He went so far as to say "get that son of a bitch off the field", referring to any black player that decided to kneel [@graham2017donald]. We predict that the increased racial tension caused by the president might be measurable in this study.  

As seen from the previous study, some players were barely mentioned on Twitter, even during the most watched football game of the year. However, we observe that players from two positions in particular were mentioned a lot: quarterbacks and receivers. To ensure that we could gather enough tweets to measure sentiments over a single game, we have decided to limit our sample to only quarterbacks and receivers as they seem to be the most popular positions on Twitter.

In order to get closer to making causal connections between sentiment and race, we need to ensure that there are an equal number of white and black quarterbacks and receivers. As we have already decided to focus in on 2017, we began creating our subset by researching which teams had starting quarterbacks who were black. The total for 2017 was 8 out of 32 teams. Then, we found that four of these eight teams also had a top receiver who was white and a top receiver who was black. These four black quarterbacks and the eight corresponding receivers (one white and one black from each team) made up the first half of the subset. To create a balanced design, four white quarterbacks were chosen by determining who was the closest in total yards for the 2017 season for each black quarterback. After ensuring that these quarterbacksâ€™ teams also had a top receiver who was black and a top receiver who was white, those 12 additional players were added to the subset. In total, tweets are gathered for the 24 chosen players. Below is a table of the players, their race, position, corresponding team.

```{r, warning = FALSE, message=FALSE, echo = FALSE}
subset <- read.csv("/Users/juliannaalvord/Documents/nfl sentiment/final_data/final_subset.csv", stringsAsFactors = F)

qb <- c("Alex Smith", "Jameis Winston", "Joe Flacco", "Carson Wentz", "Cam Newton", 
        "Dak Prescott", "Russell Wilson", "Andy Dalton")
  
subset <- subset %>%
  mutate(Position = ifelse(Name %in% qb, "QB", "R"))
  
subset %>%
  dplyr::select(Name, Team, Position, Race) %>%
  arrange(Team, Position) %>%
  kable(caption = "Total Subset of Study 2",
      caption.short = "subset") %>%
  kable_styling(bootstrap_options = "striped", latex_options = "hold_position")
```

Further investigation reveals that Tampa Bay had a bye during week 1 of the 2017 season and Seattle, Dallas, and Cincinnati had byes during week 6 of the 2017 season. Therefore, if we gather tweets for all 6 games, we would have missing values. Instead, we decided to choose 5 time points for each team. For the three teams with a bye during week 6, games 1-5 were chosen and for the other 5 teams, games 2-6 were chosen. In total, we would gather tweets for 24 players across 5 games. This totals to 120 different observations. Since we were limited to 250,000 tweets, approximately 2083 tweets could be gathered per player per game.

These 24 players are added to a data set. Also included are variables corresponding to their Twitter handle, race, position, and starting and ending times for each 5 games. It is important to us that the tweets are gathered during game play in order to limit extraneous factors that could affect sentiments toward a player. Given that the average NFL game time in 2016 was just above 3 hours and 8 minutes @gametime2016, we are limiting the time period to 3 hours and 15 minutes after the start of the game. 

###Searchtweets and Gathering Tweets using Python

In study 1, we used a function from the `rtweet` package in `R`. However, there is no package in `R` that supports the full-archive search method. Instead, we used a library in Python called `searchtweets` @searchtweets. Like in study 1, we are required to setup and load authentication, first online and then using the function `load_credentials()`. 

```{python, eval = FALSE, size = "small"}
premium_search_args = load_credentials("~/.twitter_keys.yaml",
                                          yaml_key="search_tweets_api",
                                          env_overwrite=False)
```

The `.twitter_keys.yaml` is a file that contains the same information loaded into the `create_token()` function of the `rtweet` package. Once the authentication process is complete, our data is loaded into the environment using the function `read_csv()` from the `pandas` library @mckinney2010data.

```{python, eval=FALSE, size = "small"}
data = pandas.read_csv("~PATH/final_subset.csv")
```

Given that we have many variables which need to change each time we run the function to gather tweets, we created three functions to simplify the process. The first takes a list of team names and filters the data for players on those teams. 

```{python, eval = FALSE, size = "small"}
def get_data(teams):
    data_1 = data[data.Team.isin(teams)]
    
    return data_1
```

The second and third functions are more complicated. They are almost exactly the same except that one searches Twitter for the players' full names and the other searches for their twitter handles. The arguments of these functions include a data set as well as start and end time identifiers. From there, either the full names within the player name column or twitter handles are made into a list. Then, to grab the start and end times, the first items from the columns that match the start and end arguments are selected and saved as objects. Once these objects have been created, the function gathers tweets using two functions from the `searchtweets` library: `gen_rule_payload()` and `ResultStream()`. The first takes a query, start time, end time, and maximum results per request specification. Our function loops through each name or twitter handle and enters it as the query. Then the start and end objects are used as the start and end times. The maximum tweets per request, 500, is kept constant. Added to the query is a string "-is:retweet", which limits the tweets to exclude those which are retweeted. The rule that is specified using the previous function is then added for the `rule_payload` argument of the `ResultStream()` function. This second function also requires the maximum number of results and pages to search through to be specified, which we kept constant at 2000 and 4, respectively. The final argument is our authentication object. 

Below is the tweet-gathering loop from one of our functions. Both entire functions can be found in the data appendix. 

```{python, eval = FALSE, size = "small"}
#running loop for tweets
    
    all_tweets = []

    for handle in newtwitter:

        rule = gen_rule_payload(handle + " -is:retweet",
                                from_date = start,
                                to_date = end,
                                results_per_call = 500)
            
        rs = ResultStream(rule_payload=rule,
                          max_results=2000,
                          max_pages=4,
                          **premium_search_args)

        tweets2 = list(rs.stream())

        [print(tweet.all_text) for tweet in tweets2[0:10]];
        
        all_tweets.extend(tweets2)
        
        time.sleep(10)
```

The next part of the function selects certain aspects of the twitter metadata and adds it to columns in a data frame. The metadata we chose are the tweets, length, tweet id, date, number of likes, number of retweets, quoted tweet indicator, quoted or retweet indicator, user enter text, retweeted tweet indicator, user mentions, profile location, screen name tweet is replying to, time created string, tweet type, and full text. This data frame which contains these metadata is returned at the end of our function. 

For each set of teams with the same starting and ending times each week, these three functions are run. Then, the two data frames containing the tweets and corresponding metadata are saved as `csv` files. Below is an example.

```{python, eval = FALSE, size = "small"}
#specifying teams with the same start and end times for week 1
teams = ["Kansas City Chiefs", "Tampa Bay Buccaneers", "Baltimore Ravens",
"Philadelphia Eagles", "Carolina Panthers"]
#filtering for those players
data_t1_1 = get_data(teams)

#gathering tweets
data_t1_1_tweets = get_tweets_name(data_t1_1, start = 'T1_start',
                                              end = 'T1_end')
data_t1_1_tweetsH = get_tweets_handle(data_t1_1, start = 'T1_start',
                                                 end = 'T1_end')

#saving tweets/metadata as .csv
data_t1_2_tweets.to_csv("~PATH/tweets_t1_1.csv", index = False)
data_t1_2_tweetsH.to_csv("~PATH/tweets_t1_1_H.csv", index = False)
```

After gathering tweets for all of the teams for each time point (week of games), all of the data frames are row binded. That larger data frame is then saved as a `csv` file.

```{python, eval = FALSE, size = "small"}
#binding tweets from t1 together
T1 = pd.concat([data_t1_1_tweets, data_t1_2_tweets, 
                data_t1_3_tweets, data_t1_4_tweets, 
                data_t1_1_tweetH, data_t1_2_tweetsH,
                data_t1_3_tweetsH, data_t1_4_tweetsH])

#saving as .csv
T1.to_csv("~PATH/tweets_t1_all.csv", index = False)
```

###Updating cleaning and sentiment analysis from Study 1

The data frames containing the tweets and metadata from each time point are loaded into `R` for cleaning. Luckily, these data have the same format as the data from the first study. Therefore, many of the same cleaning techniques are used. However, before these data frames are all combined, a column containing a time identifying string (ex. "t_1" for the tweets from the first week), is added. Then, these five data frames are row binded to create one data frame that contains all of the gathered tweets.

```{r, eval = FALSE, size = "small"}
#loading in the data
for (i in 1:length(files)) {
  
  assign(paste("t", i, sep = "_"), read.csv(paste(path, files[i], sep = "")))
  
}

#adding time column for each df
t_1 <- t_1 %>%
  mutate(time = "t_1")

t_2 <- t_2 %>%
  mutate(time = "t_2")

t_3 <- t_3 %>%
  mutate(time = "t_3")

t_4 <- t_4 %>%
  mutate(time = "t_4")

t_5 <- t_5 %>%
  mutate(time = "t_5")

#row_binding the three times
full <- bind_rows(t_1, t_2, t_3, t_4, t_5)
```

From there, the same cleaning techniques from study 1 are employed. One final step is to join the tweets with a data frame of the game outcomes. 

```{r, eval = FALSE, size = "small"}
tweets_final <- tweets_final %>%
  left_join(outcomes, by = c("Team", "time"))
```

### Sentiment Analysis

Again, our functions and techniques from the previous study are employed with slight variations. From the last study, I found that certain words commonly used by by football fans on Twitter are not included in the lexicon but are used as positive sentiments. The first step for sentiment analysis of this study is to add these words as rows to the end of the bing lexicon data frame. 

```{r, eval = FALSE, size = "small"}
#creating data frame with additional sentiments
extra<-data.frame(c("rings", "ring", "history", "clutch", 
                    "congrats", "dynasty", "goat", "g.o.a.t."), 
               c("positive", "positive", "positive", "positive", 
                 "positive", "positive", "positive", "positive"))
names(extra) <- c("word", "sentiment")

#binding to bing lexicon
bing_lex <- get_sentiments("bing")

sent_full <- rbind(bing_lex, extra)
```

From there, the same loop run in the previous study could be utilized if we wanted the positive and negative word counts for each player across all five time points. However, for the purpose of our study, we wrote an altered function that determines the sentiments for each player at each time point. This was done by adding a time argument that filters the tweets for that time point. Also, within the function, the other variables of total sentiment, negative word percentage, positive word percentage, time, and player name are added to the counts data frame. 

```{r, eval = FALSE, size = "small"}
sent_tall <- function(t){
  
names <- as.list(subset2$name_clean)

datalist = list()

for(i in 1:24) {
  
  #filter for each person and the correct time
  tweets <- tweets_final %>%
    filter(name_clean_final == names[i],
           time == paste0("t_", t))
  
  #pick out words
  words <- tweets %>% 
    select(ID, full_text_low) %>% 
    unnest_tokens(word,full_text_low)
  
  #creating df of stop words  
  my_stop_words <- stop_words %>% 
    select(-lexicon) %>% 
    bind_rows(data.frame(word = c("https", "t.co", "rt", "amp",
                                  "4yig9gzh5t","fyy2ceydhi","78","fakenews")))

  #anti-join with stop words to filter those words out
  tweet_words <- words %>% 
    anti_join(my_stop_words)

  #joining sentiments with non-stop words from tweets
  fn_sentiment <- tweet_words %>% 
    left_join(sent_full) 
  
  #creating df with n of sentiments
  df <- fn_sentiment %>% 
    filter(!is.na(sentiment)) %>% 
    group_by(sentiment) %>% 
    summarise(n=n())

  #making df of sentiments for each person
  df_2 <- df %>%
  mutate(player = names[i]) %>%
  spread(key = sentiment, value = n)
  
  datalist[[i]] <- df_2

}

sentiment_full <- do.call(bind_rows, datalist)

sentiment_full <- sentiment_full %>%
  mutate(totalsentiment = negative + positive,
         neg_perc = negative/totalsentiment * 100,
         pos_perc = positive/totalsentiment *100,
         time = paste0("t_", t),
         player = as.character(player))
  
return(sentiment_full)

}
```

This function is run 5 times to determine sentiments for each of the five time points. These are rowbinded to create a data frame with 120 rows (24 players * 5 time points). Then, it is joined with the subset dataframe that contains 5 rows per player to include outcome per time point. 

```{r, eval = FALSE, size = "small"}
#sentiments for time 1
sent_tall_1 <- sent_tall(1)

#sentiment for time 2
sent_tall_2 <- sent_tall(2)

#sentiment for time 3
sent_tall_3 <- sent_tall(3)

#sentiment for time 4
sent_tall_4 <- sent_tall(4)

#sentiment for time 5
sent_tall_5 <- sent_tall(5)

#combining outcome to players
outcomes_players <- subset2 %>%
  full_join(outcomes, by = "Team")

#row_binding all of the sentiments together
sent_tall_full <- sent_tall_1 %>%
  bind_rows(sent_tall_2, sent_tall_3, sent_tall_4, sent_tall_5)

#joining sentiment tall to outcomes
sent_tall_full1 <- outcomes_players %>%
  left_join(sent_tall_full, by = c("name_clean" = "player", "time"))
```

The data frame created here is the final one to be used in our model. However, one additional variable is added to account for individual performance during a game. To gather game level data, we use the `nflscrapR` package in `R` [@nflscrapr]. First, we use the `scrape_game_ids()` function to gather the game ids for the first 6 weeks of the 2017 season. Then, we filtered for only the teams included in our subset.

```{r, eval = FALSE, size = "small"}
#gathering game ids for first 6 weeks in 2017
week1_to_6 <- scrape_game_ids(2017, weeks = c(1, 2, 3, 4, 5, 6))

#specifying 8 teams from subset
teams <- c("CIN", "DAL", "SEA", "CAR", "TB", "PHI", "KC", "BAL")

#filtering dataset for only those 8 teams
week1_to_6_filt <- week1_to_6 %>%
  filter(home_team %in% teams | away_team %in% teams)
```

After that, 6 dataframes were created that each containe the game ids for the corresponding week. Weeks 1 and 6 had additional filtering arguments to filter for the correct teams. From there, a column that included a players first initial and last name is added to the subset df. For each week, the game ids are added to a list. Then, a loop iterates through them and stats for that game are added to a different list (as a data frame) using the `player_game()` function of the `nflscrapr` package. Those data frames are subsequently rowbinded. Once the data frame containing all the stats for the games of that week is created, it is filtered for the players of our subset. The variable of yards per game is creating by combining the three columns of passing yards, rushing yards, and receiving yards. 

```{r, eval = FALSE, size = "small"}
##week 2
#game ids added to list
week2 <- as.list(week2$game_id)

stats <- list()

#looping through game ids to get stats 
for (i in 1:7) {
  
  df <- player_game(week2[i])
  
  stats[[i]] <- df
  
}

#binding data frames with stats
week2_stats <- do.call(bind_rows, stats)

#pulling out names
names_week2 <- subset2$name_2

#creating long string of all names
all_name2 <- paste(names_week2, collapse='|')

week2_stats <- week2_stats %>%
  #filtering for name matches
  mutate(match = ifelse(grepl(all_name2, name), 1, 0)) %>%
  filter(match == 1, !(name == "R.Wilson" & Team == "KC")) %>%
  select(name, Team,  passyds, rushyds, recyds) %>%
  #creating full yards and time columns
  mutate(full_yards = passyds+ rushyds+ recyds,
         time = ifelse(Team %in% week_1, "t_2", "t_1")) %>%
  select(name, Team, full_yards, time)
```

This process is completed for each week. Then, the resulting data frames are rowbinded and joined on the model data by name and time. One final adjustment is made to our yards variable in order to standardize yards for quarterbacks and receivers. As quarterbacks can gain yardage through multiple receivers but receivers can only gain yardage on their own, the yards are on two different scales. The common ratio of yards for quarterbacks to receivers is 3:1, with 300 and 100 yard games for quarterbacks and receivers, respectively, indicating successful games. To standardize, the number of total yards for quarterbacks is divided by 3. 

###Modeling

As stated earlier, the chosen modeling approach for this project is multi-level modeling. If a more simple modeling approach is used, we would not be accounting for the dependence in our data and the estimates of the coefficients would be less accurate. The lowest level in our data contains the repeated observations for each player, with that variable being the yards per game. The second level in our data contains the variables that are constant for a player and do not change, with those being race and position. The third level contains those that are constant for a team, with that being outcome. Our goal in the model is to get main effects for those four variables and an additional main effect for the interaction term between race and outcome. The results of this model will best help us answer our research question and test our hypotheses. Below are the regression equations at each of the three levels then the final equation combining those three.

Level 1:
$~$

$negperc_{tij} = \beta_{0ij} + \beta_{1ij}totalyards_{tij} + \varepsilon_{tij}$

Level 2:
$~$

$\beta_{0ij} = \Upsilon_{00j} + \Upsilon_{01j}race_{ij} + \Upsilon_{02j}position_{ij} + U_{0ij}$

$\beta_{1ij} = \Upsilon_{10j}$

Level 3:
$~$

$\Upsilon_{00j} = \delta_{000} + \delta_{001}outcome_{j} + V_{0j}$ 

$\Upsilon_{01j} = \delta_{010} + \delta_{011}outcome_{j} + V_{1j}$

$\Upsilon_{02j} = \delta_{020}$

$\Upsilon_{10j} = \delta_{100}$

First, we substitute the equations from level 2 into the equation from level 1:
$~$

\begin{align*}
negperc_{tij} = &(\Upsilon_{00j} + \Upsilon_{01j}race_{ij} + \Upsilon_{02j}position_{ij} + U_{0ij}) +\\
&(\Upsilon_{10j})totalyards_{tij} + \varepsilon_{tij}
\end{align*}
   
From there, we can substitute in the equations from level 3:
$~$

\begin{align*}
negperc_{tij} = &\delta_{000} + \delta_{001}outcome_{j} + V_{0j} + \\
&(\delta_{010} + \delta_{011}outcome_{j} + V_{1j})race_{ij} + \\
&(\delta_{020})position_{ij} + U_{0ij}) +\\
&(\delta_{100})totalyards_{tij} + \varepsilon_{tij}
\end{align*}


In final form, with all of the variables in the correct order, is written as:
$~$
\begin{align*}
negperc_{tij} = &\delta_{000} + \delta_{001}outcome_{j} + \delta_{010}race_{ij} +\\
&\delta_{020}position_{ij} + \delta_{100}totalyards_{tij} +\\
&\delta_{011}outcome_{j}race_{ij} + V_{0j} + V_{1j}race_{ij} + &U_{0ij} + \varepsilon_{tij}
\end{align*}

The fixed effects of this model include $\delta_{000}$, $\delta_{001}$, $\delta_{010}$, $\delta_{020}$, $\delta_{100}$, and $\delta_{020}$. The third level random effects are $V_{0j}$ and $V_{1j}$ which account for the random variance of means between teams. The second level random effect is $U_{0ij}$, which accounts for random variance of means for players within teams. Finally, the first level random effect is $\varepsilon_{tij}$, which accounts for random variance of means for players within teams across the five time points. These random effects are assumed to have means at zero and be normally distributed. 

There are multiple reasons why we chose to use multilevel regression modeling instead of regular linear regression modeling. The main reason we chose this technique is because of the heirarchical nature of our data. If we did not account for the random variance at each level, we would be treating each observation as idependent when they are not. In that case, the standard errors will be underestimated and significance will be overstated. The standard errors for coefficients of higher-level predictor variables will be most affected. This could lead to more type I errors.

The normal method to estimate coefficients in multilevel regression is the maximum likelihood method. This method is a general estimation procedure, which creates estimates of the population parameters that maximize the probability (maximum likelihood) of observing the data that are actually observed, given the model. The benefits of this estimation method is that it is generally robust, and produces estimates that are asymptotically efficient and consistent. However, in this study, our regression coefficients are estimated using a slightly altered method, known as REML (restricted maximum likelihood). During estimation using this method, only the variance components are a part of the likelihood function, and the coefficients are estimated in a second estimation step. This produces parameter estimates with associated standard errors as well as an overall deviance, which is a function of the likelihood [@hox2010multilevel]. The reason for using REML instead of the standard ML is due to our small sample size. The REML method estimates the random effects after removing the fixed effects of the model. Unlike other methods, which do not account for the degrees of freedom lost by estimating fixed effects, REML produced estimates that are less biased in smaller sample sizes.

To fit the above model in `R`, the `nlme` package is used [@nlme]. The function used is `lme()`, which in our case, took three arguments: the fixed effects, the random effects, and the data. The code used is below. 

```{r, eval = FALSE, size = "small"}
mlm_model <- lme(neg_perc ~ outcome * Race + position + yards_fixed,
               random = ~ 1 | Team.x/name_2, data = data2)
```

##Results

###Summary Statistics
```{r, include = FALSE}
full_stats <- read.csv("/Users/juliannaalvord/Documents/nfl sentiment/final_data/full_stats.csv")

model_data <- read.csv("/Users/juliannaalvord/Documents/nfl sentiment/final_data/use_for_model1.csv", stringsAsFactors = F)

qb <- c("alex smith", "jameis winston", "joe flacco", "carson wentz", "cam newton", 
        "dak prescott", "russell wilson", "andy dalton")

#adding in position
model_data <- model_data %>%
  mutate(position = ifelse(name_clean %in% qb, "qb", "r"))

model_data <- model_data %>%
  separate(Name, c("first", "last"), " ") %>%
  mutate(first_init = substr(first, 1, 1),
         last = ifelse(last == "Jeffrey", "Jeffery", last),
         name_2 = paste(first_init, last, sep = ".")) %>%
  left_join(full_stats, by = c("name_2" = "name", "time" = "time"))

#filtering missing sentiments
data2 <- model_data %>%
  filter(!is.na(neg_perc)) %>%
  mutate(win_bin = ifelse(outcome == "W", 1, 0),
         lose_bin = ifelse(outcome == "L", 1, 0),
         black_bin = ifelse(Race == "B", 1, 0))


data2 <- data2 %>%
  mutate(yards_fixed = ifelse(position == "qb", full_yards/3, full_yards))
```

The mean percentage of negative words across all time points and players is `r round(mean(data2$neg_perc), 1)`%. This variable is fairly normally distributed, with a slight left scew.

```{r, echo = FALSE, fig.cap="Histogram of Response Variable"}
ggplot(data2, aes(neg_perc)) + geom_histogram(bins = 10) +
  theme_classic()+
  theme(axis.title.y = element_blank()) +
  xlab("Percentage of Negative Words")
```

When breaking down by race and outcome, our two main variables of focus, the median percentage of negative words for a win is 46.2% for black players and 46.89% for white players. For a loss, the mean percentage of negative words is 65.17% for black players and 58.96%. 

```{r, include=FALSE}
sent_tall_full1 <- read.csv("/Users/juliannaalvord/Documents/nfl sentiment/final_data/use_for_model1.csv", stringsAsFactors = F)
```

```{r, echo = FALSE, fig.cap="Mean Percentage of Negative Words across Race and Outcome"}
sent_tall_full1$outcome1 <- factor(sent_tall_full1$outcome, labels = c("Lost", "Won"))

#gathering by race, player and sentiment
subset_sent_format <- sent_tall_full1 %>%
  dplyr::select(name_clean, Race, outcome1, 21:22) %>%
  gather(sentiment, n, 4:5)

#grouping by sentiment and race then making mean for each sentiment/race
subset_sent_2 <- subset_sent_format %>%
  dplyr::group_by(sentiment, Race, outcome1) %>%
  summarise(mean_perc_sent = mean(n, na.rm = T))

subset_sent_2 <- subset_sent_2 %>%
  filter(sentiment == "neg_perc")

#same viz but by outcome as well
ggplot(subset_sent_2, aes(x = sentiment, y = mean_perc_sent, fill = Race)) +
  geom_bar(stat = "identity", position = "dodge", color = "black") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_fill_manual(values=c("black", "white")) + facet_wrap(~outcome1) +
  theme_bw() +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank()) +
  xlab("Percentage of Negative Words") +
  ylab("Average Percentage of Total Sentiment") +
  geom_text(
    aes(label = round(mean_perc_sent, digits = 2), y = mean_perc_sent + 1),
    position = position_dodge(0.9),
    vjust = 0
  )
```


###Multi-level Model

Below is a table with the results of our model. 
```{r, message=FALSE, warning=FALSE, include = FALSE}
mlm_model <- lme(neg_perc ~ outcome * Race + position + yards_fixed,
               random = ~ 1 | Team.x/name_2, data = data2)
#summary(mlm_model)
```

----------------------------------------------------------------------------------
  Variable                  Estimation      St.Error        p-Value
------------------------- -------------- -------------- --------------
  Intercept                    74.21          4.85           0.00
  
  OutcomeW                    -19.08          3.12           0.00  
  
  RaceW                        -7.22          3.90           0.08
  
  PositionR                    -4.11          3.24           0.22
  
  Fixed Yards                  -0.09          0.04           0.02
  
  OutcomeW:RaceW                6.72          4.59           0.15
------------------------- --------------- -------------- --------------
Table: (\#tab:tab1) Estimates of $\delta$ coefficients from our multilevel regression model

The resulting formula with the $\delta$ coefficients included is as follows:

\begin{align*}
{negperc} = &74.21 - 19.08\widehat{OutcomeW} - 7.22\widehat{RaceW} - 4.11\widehat{PositionR} -\\
&0.09\widehat{Yards} + 6.74\widehat{OutcomeW:RaceW}
\end{align*}

The intercept, $\delta_{000}$, of 74.21 means that the average percentage of negative words for black players during a loss is 74.21%, holding position and yards constant. The $\delta_{001}$ coefficient estimate of -19.08 means that on average, the percentage of negative words for black players decreases by 19.08% during a win, holding position and yards constant. This coefficient estimate is significant, p < 0.05. The $\delta_{010}$ coefficient estimate of -7.22 means that on average, the percentage of negative words during a loss decreases by 7.22% for white players, holding position and yards constant. This coefficient estimate is not significant, p > 0.05. The $\delta_{020}$ coefficient estimate of -4.11 means that on average, the percentage of negative words during a loss for black players decreases by 4.11% for receivers, holding yards constant. This coefficient estimate is not significant, p > 0.05. The $\delta_{100}$ coefficient estimate of -0.09 means that on average, for each 1 additional yard gained by a player, the percentage of negative words for black players during a win decreases by 0.09%, holding position constant. This coefficient estimate is significant, p < 0.05. The coefficient estimate of 6.72 for the intercept between race and outcome means that during a win, the percentage of negative words for white players increases by 6.72%, holding position and yards constant. This coefficient estimate is not significant, p > 0.05.

### ICC

The intraclass correlation (ICC) in multilevel modeling indicates the proportion of the variance explained by the clustered structure and is measured by dividing the variance for that level over the total variance:

$ICC_{V_j} = \sigma_{V_j}^2/\sigma_{V_j}^2+\sigma_{U_ij}^2+\sigma_{\epsilon_tij}^2$

$~$

$ICC_{U_ij} = \sigma_{U_ij}^2/\sigma_{V_j}^2+\sigma_{U_ij}^2+\sigma_{\epsilon_tij}^2$

$~$

For our model, the ICC is 0.05 for level 3 (team level) and .12 for level 2 (player level). These numbers inform us that we have very little team variance but slightly higher player variance. Generally, this means that there is little evidence that football fans on Twitter feel more or less negatively about certain teams but slightly stronger evidence that they feel more or less negatively about certain players. Though these numbers are small, we do not believe that this is sufficient evidence to treat our observations as indepedent. Therefore, these results further confirm that the use of multilevel regression to account for these variances at each level is necessary. 

### Baseline Linear Regression Model

For comparison, below are the results of a baseline logistic regression model which cannot pick up the random variance of our data.

```{r, echo = FALSE, include = FALSE}
model_lm <- lm(neg_perc ~ outcome * Race + position + yards_fixed, data = data2)

#summary(model_lm)
```

----------------------------------------------------------------------------------
  Variable                  Estimation      St.Error        p-Value
------------------------- -------------- -------------- --------------
  Intercept                    73.37          4.57           0.00
  
  OutcomeW                    -18.92          3.33           0.00  
  
  RaceW                        -7.26          3.66           0.05
  
  PositionR                    -3.67          2.76           0.19
  
  Fixed Yards                  -0.08          0.04           0.04
  
  OutcomeW:RaceW                7.33          4.87           0.13
------------------------- --------------- -------------- --------------
Table: (\#tab:tab2) Estimates of $\beta$ coefficients from basic linear regression model

As seen from tables \@ref(tab:tab1) and \@ref(tab:tab2), there are differences between coefficients, standard errors, and p-values. Almost all of the p-values that correspond to the coefficient estimates are smaller from the linear regression model.

##Discussion

To begin, our results suggest that there is a signficant relationship between outcome and percentage of negative words. The negative direction of this coefficient, meaning that a win results in a lower percentage of negative words, assured us that our data is realiable. If the percentage of negative words increased during a win, we would be suspicious that our data is not credible. This direction informs us that during a positive outcome, the percentage of negative words towards players decreases. This confirmes our first hypothesis. The direction of the other significant variable, total yards, also suggests that better performance leads to a lower percentage of negative words, another indication of reliable data.

The main research question for this project mainly involved differences between white and black players. To reiterate, our research question was: Are sentiments on Twitter more negative towards black NFL players after controlling for game outcome and quality of play? We also hypothesized that during a game that was lost, sentiments would be more negative toward black players. Though our race variable is not signficant at the 0.05 level, it's negative direction matches what we hypothesized. The coefficient estimate indicates that during a loss, sentiments are more negative towards black players. However, our interaction variable suggests that this difference is much smaller during a game that is won. For a white player during a win, the percentage of a negative words is only 0.5% (-7.22% + 6.72%) lower compared to black players. While again not significant, our model does directionally match our hypothesis. 

While our model's coefficient estimate for position was negative, meaning that receivers receive fewer negative sentiments on average than quarterbacks, this is not significant. We did not expect there to be differences between the two positions but included this variable in order to control for position while investigating the relationship between race, outcome, and percentage of negative words.

Our results are consistent with other studies that found that language for black and white football players is unequal, with black players receiving more negative sentiments than white players, especially during a loss. This disparity is evidence of racial microaggressions from sports fans, a phenomenom rarely studied without survey data. Unlike other research, this study uses data on a much larger scale to quantify previous findings. As stated in chapter 1, @hylton2016your argues that further research involving more subtle forms of racism and racial discrimination in sports is necessary. Through this study, one of our main goals is to shed light on a subtle form of racism which takes form through racially disproportionate negative language.

###Limitations and Future Directions

These results should be considered in light of their limitations. First, some players are missing data at certain time points. This means that no positive or negative words were included in the tweets for those players at that time point. This lowered our already small sample size which can have an affect on the validity of our results. The small sample size was partially due to the Twitter API limits. In order to gather enough tweets to find positive and negative words, we could not have realistically added more time points. If we were able to gather more than 250,000 tweets, we could have added more time points while still gathering enough tweets for sentiment analyses. This would have increased our sample size and made our estimates more accurate. By doing so, important relationships may have be revealed.

Additionally, this study only gathers tweets for 24 players, which is a small subset of the entire NFL roster of quarterbacks and receivers. With more players added to the study, our results may be more generalizable. In the future, it would be beneficial to gain higher access to Twitter's API search. Unfortunately, this would require a larger monetary contribution which was not possible in the current study. Luckily, as seen from Study 1, there are other methods of accessing the API which are free. With enough planning, tweets could be gathered using the streaming method during the games of the upcoming season. This would both increase the subset of players and number of total tweets. 

Another limitation to this study is that the race of the players is based on our perception and could be unreliable. In the future, having multiple people offer their perceptions of the players' races could improve results and reduce biases. In addition to the race variable, adding more demographic data about the players or extra variables of individual performance could better disseminate the relationship of interest from our research question.  

Nevertheless, these limitations are offset by strengths. The balanced nature of this study allowed us to get closer to making causal claims of racial impacts on the percentage of negative words. Furthermore, though it would have been favorable to gather more tweets, this study used more data than many previous studies and therefore offers previously untapped quantitative insights. 

