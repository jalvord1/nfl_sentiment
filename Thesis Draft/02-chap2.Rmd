# Ethics {#ethics}

##Data Ethics Overview

The recent increases in data access offer a unique opportunity for companies and researchers to gain insights that would otherwise be impossible to determine. These insights could lead to better disease tracking, optimization of business practices, or streamlining something, to name a few examples. The benefits of using data in research across all disciplines are extensive and cannot be understated. However, ensuring that the data usage is ethical and fair is a vital step in the process. 

As helpful as data can be, it can be equally as damaging and dangerous if used without consideration of the ethical consequences. As stated by @mittelstadt2016ethics, researchers utilizing big data must have ethical foresight instead of ethical hindsight as the consequences are substantial. While important, many do not focus on ethics or issues of bias. Often, these issues stem from a lack of contextual understanding of data and data science techniques [@taylor2016no]. Additionally, there is a lack of a universal code of conduct for data scientists. As data can be used by researchers in any domain, knowledge of ethical issues of statistics and data analysis is not widespread. We will begin by combining multiple sources to create a thorough ethics guide, specifically relating to research involving web scraping. 

### Theory-Driven Web Scraping

@landers2016primer argue that when scraping data from the web, researchers must follow a hypothetico-deductive modeling approach. This means that data is scraped with a hypothesis in mind and is gathered in order to test the hypothesis or answer a research question. This directs researchers away from hypothesizing after the results are already known. When data is scraped without a specific research question and the study design is unbalanced, it may be more likely for issues of content or construct validity to occur. These may go undetected and demonstrate results that do not accurately represent the phenomenon. The concept of creating a hypothesis after data is collected and analyzed is known as *post-hoc hypothesizing*. It is important to differentiate between presenting post-hoc hypotheses as a priori (PPHA) and presenting post-hoc hypotheses as those which require future empirical verification [@leung2011presenting]. The latter represents an acceptable process of research, whereas the former is considered unethical in most research domains.

@leung2011presenting specifies three types of widespread PPHA. In the first case, researchers create hypotheses directly from their results in order for their study to be theoretically compelling. In the second case, researchers will simply drop hypotheses that are dis-confirmed and fail to introduce them at all. In the third and final case, hypotheses may be added that appear to match the results but are presented a priori. These methods lack the transparency necessary for ethical research practices. This type of post-hoc hypothesizing fails to account for previously studied relevant theoretical concepts, an important aspect of the research process. These issues can be magnified when using data scraped from the web, as larger sample sizes could lead to more significant results. These studies may be more publishable and therefore, ethically questionable research may direct future work on the topic. 

Additionally, investigators must recognize that results using scraped data cannot be generalized to the entire population, even if the sample appears widespread. The reason for this, specified by @wallace2015psychology, is that internet users are inherently different than those who are not on the internet. If the goal is to generalize toward other internet users, that is acceptable in certain cases. However, it is unethical to assume results can be generalized any further. 

### Identifiability

Another important ethical issue of web scraping that must be considered is identifiability. Data from online sources often contain identifying information, even if it does not initially appear so. Data that can be used to distinguish or trace identities either alone or in combination with other information that linkable to an individual is known as personally identifiable information [@krishnamurthy2009leakage]. Given the huge increases in social network use, scandals involving data from these sources have been all over the news. Facebook, in particular, has come under scrutiny for their lack of data privacy and transparency. In 2008, Facebook announced that an attack on their server resulted in the exposure of the personal data from over 50 million users [@facebookbreach]. While alarming, PII can be leaked without hacking systems. The ability for researchers to use APIs or other computer science techniques to scrape data from these sites has also resulted in an improper distribution of PII. As an example, researchers Emil Kirkegaard and Julius Daugbjerg Bjerrek√¶r scraped data from OkCupid then released the data set for other researchers to use. However, the data included identifiable information of users, including their sexual preferences, politics, and feelings about homosexuality, among others [@resnick2016researchers to get]. 

When Kirkegaard was questioned about this ethical breach, he argued that the data were already public and therefore their scraped data was simply making the information accessible for research [@resnick2016researchers to get]. This example brings light to the delicate balance of data accessibility and privacy. While reproducibility of research is important, avoiding ethical issues that arise when PII must be given equal attention. Often, determining that line is left up to the discretion of the researcher. Therefore, it is necessary for researchers to be constantly aware of the ethical consequences of gathering and sharing data. In the context of the OkCupid example and the argument from the primary investigator, while the data was technically public, the users did not consent for their data to be used and shared for research outside of the OkCupid website. 

Sharing PII can result in consequences that extend beyond simply a lack of consent. @floridi2016data warn that it can lead to serious problems that range from group discrimination (racism, sexism, ageism, etc.) to group-targeted forms of violence. When evaluating the multiple ethical concerns of big data research, the solution is to follow the two moral duties introduced by @floridi2014open: to foster human rights and improve human welfare. If that is the ultimate goal of the research, ethical concerns will be minimized.

### Connection to this Research

Throughout the process of this research, we addressed and attempted to avoid any and all ethical concerns. First, we followed the theory-driven web scraping approach when connecting to the Twitter API to gather tweets. Our study was designed purposefully to answer our research question and test our hypothesis. We did not hypothesize post-hoc a priori nor did we generalize our results to populations past football fans who use Twitter. 

While gathering tweets through the Twitter streaming and full-archive APIs, we only selected certain meta-data to be included in our final data sets. These did not include usernames, IDs, or other personally identifiable information. Our goal was to analyze sentiments from the words of the tweets and was not at all related to the specific users who produced said tweets. As our code used to gather the tweets is uploaded to GitHub, another researcher could alter the functions we wrote to include identifying variables into the data set. That being said, only a person with data science skills would be able to do so and we expect those using data science techniques to gather data will follow ethical practices. 
