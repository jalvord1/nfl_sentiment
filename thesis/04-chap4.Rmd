```{r include = FALSE}
library(httr)
library(twitteR)
library(rtweet)
library(dplyr)
library(readr)
library(ggplot2)
library(rvest)
library(magrittr)
library(tidyr)
library(stringr)
library(tidytext)
library(scales)
library(kableExtra)
library(lme4)
library(lavaan)
library(nlme)
library(semPlot)
library(stats)
library(visreg)
library(knitr)
library(reticulate)
```

#Study 2- Modeling Percentages of Negative Words

##Introduction

After gathering the analyzing tweets posted during the Super Bowl, we created a balanced study that would allow us to build models to determine if there are significant relationships between race, outcome, and percentage of negative tweets. As previously stated, our research question is: Are sentiments on Twitter more negative towards black NFL players after controlling for game outcome, positive, and quality of play? In order to add observations to this analysis, we are including multiple games as separate time points. 

We have two main hypotheses. First, we hypothesize that during a game that was won, sentiments will be less negative than during games that were lost. Second, we hypothesize that during a game that was lost, sentiments will be more negative toward black players, whereas this difference will be smaller, or zero, in games that were won. 

##Methods

###Full-Archive Twitter API

In order to gather tweets through Twitter's APIs, three options are available: the standard, 30-day archive, and the full-archive searches. Within the advanced search methods (30-day and full archive), there is a free "sandbox" option to allow researchers to test applications or other functions. The details of these can be found in Chapter 1. Given our desire to focus on games from 2017, the chosen method for this project is the premium full-archive search. This method has strict limits in terms of the number of tweets that can be scraped per month. Below is an image that specifies these limits.

```{r, echo = FALSE, fig.cap="Twitter Full-Archive Search Limits", out.width = "475px"}
include_graphics(path = "api_limits.png", auto_pdf = TRUE)
```

In addition to these limits, there are monthly limits which depend on the level of access that is selected. We chose a 500/month request limit for this project. Therefore, with 500 requests per month and 500 tweets per request, we are capped at 250,000 tweets total. This constraint determined and influenced many decisions of this study, especially in regard to the choice of players to include in our sample. 

###Chosen Games and Sample

Initially, when beginning this project, we hoped to use individual plays of a game as the observational level. We looked to use play-by-play data that was gathered earlier and match the time of plays to the time of tweets. Included in this dataset were plays from the first six games of the 2017 season. However, due to discrepencies in the time variables and other restraints, this was not possible. Regardless, we are choosing to continue to focus on those specific games. First, we believe that six games allows us enough time points while still giving us the ability to gather enough tweets to accurately measure and model sentiments. More details on this decision are below. Moreover, in 2017 US President Donald Trump attacked NFL players who had chosen to kneel in support of Colin Kaepernick on multiple platforms. He went so far as to say "get that son of a bitch off the field," referring to any black player that decided to kneel [@graham2017donald]. We predict that the increased racial tension inflated by the president might be measurable in this study.  

As seen from the previous study, some players were barely mentioned on Twitter, even during the most watched football game of the year. However, we observe that players from two positions in particular were mentioned a lot: quarterbacks and receivers. To ensure that we could gather enough tweets to measure sentiments over a single game, we have decided to limit our sample to only quarterbacks and receivers as they seem to be the most popular positions on Twitter.

In order to get closer to making causal connections between sentiment and race, we needed to ensure that there are an equal number of white and black quarterbacks and receivers. As we have already decided to focus in on 2017, we began creating our subset by researching which teams had starting quarterbacks who were black. The total for 2017 was 8 out of 32 teams. Then, we found that four of these eight teams also had a top receiver who was white and a top receiver who was black. These four black quarterbacks and the eight corresponding receivers (one white and one black from each team) made up the first half of the subset. To create a balanced design, we chose four white quarterbacks by determining who was the closest in total yards for the 2017 season for each black quarterback. After ensuring that these quarterbacksâ€™ teams also had a top receiver who was black and a top receiver who was white, those 12 additional players were added to the subset. In total, tweets are gathered for the 24 chosen players. 

Had we instead randomly chosen 12 white and 12 black players with 8 being quarterbacks and 16 being receivers, the majority of the quarterbacks would likely have been white and the majority of the receivers would likely have been black. The reasoning behind this is that the majority of quarterbacks in the NFL are white whereas the majority of receivers are black. Had we not purposefully balanced our design, the race and positions variables would have been confounded and including them both in our model would add complexity without adding new information.  

Below is a table of the players, their race, position, corresponding team.

```{r, warning = FALSE, message=FALSE, include = FALSE}
subset <- read.csv("/Users/juliannaalvord/Documents/nfl sentiment/final_data/final_subset.csv", stringsAsFactors = F)

qb <- c("Alex Smith", "Jameis Winston", "Joe Flacco", "Carson Wentz", "Cam Newton", 
        "Dak Prescott", "Russell Wilson", "Andy Dalton")
  
subset <- subset %>%
  mutate(Position = ifelse(Name %in% qb, "QB", "R"))
```

```{r subset, warning=FALSE, message=FALSE, echo=FALSE}
subset %>%
  dplyr::select(Name, Team, Position, Race) %>%
  arrange(Team, Position) %>%
  kable(caption = "Total Subset of Study 2",
      caption.short = "Total Subset of Study 2") %>%
  kable_styling(bootstrap_options = "striped", latex_options = "hold_position")
```

Further investigation reveals that Tampa Bay had a bye during week 1 of the 2017 season and Seattle, Dallas, and Cincinnati had byes during week 6 of the 2017 season. Therefore, if we gather tweets for all 6 games, we would have missing values. Instead, we decided to choose 5 time points for each team. For the three teams with a bye during week 6, games 1-5 were chosen and for the other 5 teams, games 2-6 were chosen. In total, we would gather tweets for 24 players across 5 games. This totals 120 different observations. Since we are limited to 250,000 tweets, approximately 2083 tweets could be gathered per player per game.

These 24 players are added to a data set shown in Table \@ref(tab:subset). Also included are variables corresponding to their Twitter handle, race, position, and starting and ending times for each 5 games. It is important to us that the tweets are gathered during game play in order to limit extraneous factors that could affect sentiments toward a player. Given that the average NFL game time in 2016 was just above 3 hours and 8 minutes @gametime2016, we are limiting the time period to 3 hours and 15 minutes after the start of the game.

Race is determined by our own perceptions. To avoid our biases, it would be ideal to determine race by a personally identified racial/ethnic code. However, this information is not available.

###Searchtweets and Gathering Tweets using Python

In Chapter 3, we use a function from the `rtweet` package in `R`. However, there is no package in `R` that supports the full-archive search method. Instead, we used a library in Python called `searchtweets` [@searchtweets]. Like in Chapter 3, we are required to setup and load authentication, first online and then using the function `load_credentials()`. 

```{python, eval = FALSE, size = "small"}
premium_search_args = load_credentials("~/.twitter_keys.yaml",
                                          yaml_key="search_tweets_api",
                                          env_overwrite=False)
```

The `.twitter_keys.yaml` is a file that contains the same information loaded into the `create_token()` function of the `rtweet` package. Once the authentication process is complete, our data is loaded into the environment using the function `read_csv()` from the `pandas` library [@mckinney2010data].

```{python, eval=FALSE, size = "small"}
data = pandas.read_csv("~PATH/final_subset.csv")
```

Given that we have many variables which need to change each time we run the function to gather tweets, we created three functions to simplify the process. The first takes a list of team names and filters the data for players on those teams. 

```{python, eval = FALSE, size = "small"}
def get_data(teams):
    data_1 = data[data.Team.isin(teams)]
    return data_1
```

The second and third functions are more complex. They are almost exactly the same except that one searches Twitter for the players' full names and the other searches for their twitter handles. The arguments of these functions include a data set as well as start and end time identifiers. From there, either the full names within the player name column or twitter handles are made into a list. Then, to grab the start and end times, the first items from the columns that match the start and end arguments are selected and saved as objects. Once these objects have been created, the function gathers tweets using two functions from the `searchtweets` library: `gen_rule_payload()` and `ResultStream()`. The first takes a query, start time, end time, and maximum results per request specification. Our function loops through each name or twitter handle and enters it as the query. Then the start and end objects are used as the start and end times. The maximum tweets per request, 500, is kept constant. Added to the query is a string `-is:retweet`, which limits the tweets to exclude those which are retweeted. The rule that is specified using the previous function is then added for the `rule_payload` argument of the `ResultStream()` function. This second function also requires the maximum number of results and pages to search through to be specified, which we kept constant at 2000 and 4, respectively. The final argument is our authentication object. 

Below is the tweet-gathering loop from one of our functions. The entire function that searches for players' full names can be found in the data appendix. 

```{python, eval = FALSE, size = "small"}
#running loop for tweets
    
    all_tweets = []

    for handle in newtwitter:

        rule = gen_rule_payload(handle + " -is:retweet",
                                from_date = start,
                                to_date = end,
                                results_per_call = 500)
            
        rs = ResultStream(rule_payload=rule,
                          max_results=2000,
                          max_pages=4,
                          **premium_search_args)

        tweets2 = list(rs.stream())

        [print(tweet.all_text) for tweet in tweets2[0:10]];
        
        all_tweets.extend(tweets2)
        
        time.sleep(10)
```

The next part of the function selects certain aspects of the twitter metadata and adds it to columns in a data frame. The metadata we chose are the tweets, length, tweet id, date, number of likes, number of retweets, quoted tweet indicator, quoted or retweet indicator, user enter text, retweeted tweet indicator, user mentions, profile location, screen name tweet is replying to, time created string, tweet type, and full text. This data frame which contains these metadata is returned at the end of our function. 

For each set of teams with the same starting and ending times each week, these three functions are run. Then, the two data frames containing the tweets and corresponding metadata are saved as files. Below is an example.

```{python, eval = FALSE, size = "small"}
#specifying teams with the same start and end times for week 1
teams = ["Kansas City Chiefs", "Tampa Bay Buccaneers", "Baltimore Ravens",
"Philadelphia Eagles", "Carolina Panthers"]
#filtering for those players
data_t1_1 = get_data(teams)

#gathering tweets
data_t1_1_tweets = get_tweets_name(data_t1_1, start = 'T1_start',
                                              end = 'T1_end')
data_t1_1_tweetsH = get_tweets_handle(data_t1_1, start = 'T1_start',
                                                 end = 'T1_end')

#saving tweets/metadata as .csv
data_t1_2_tweets.to_csv("~PATH/tweets_t1_1.csv", index = False)
data_t1_2_tweetsH.to_csv("~PATH/tweets_t1_1_H.csv", index = False)
```

After gathering tweets for all of the teams for each time point (week of games), all of the data frames are combined. That larger data frame is then saved as a file.

```{python, eval = FALSE, size = "small"}
#binding tweets from t1 together
T1 = pd.concat([data_t1_1_tweets, data_t1_2_tweets, 
                data_t1_3_tweets, data_t1_4_tweets, 
                data_t1_1_tweetH, data_t1_2_tweetsH,
                data_t1_3_tweetsH, data_t1_4_tweetsH])

#saving as .csv
T1.to_csv("~PATH/tweets_t1_all.csv", index = False)
```

###Updating cleaning and sentiment analysis from the Super Bowl

We then load the data frames containing the tweets and metadata from each time point into `R` for cleaning. Luckily, these data have the same format as the data from the first study. Therefore, many of the same cleaning techniques are used. However, before these data frames are all combined, a column containing a time identifying string (ex. `t_1` for the tweets from the first week), is added. Then, these five data frames are combined to create one data frame that contains all of the gathered tweets.

```{r, eval = FALSE, size = "small"}
#loading in the data
for (i in 1:length(files)) {
  
  assign(paste("t", i, sep = "_"), read.csv(paste(path, files[i], 
                                                  sep = "")))
  
}

#adding time column for each df
t_1 <- t_1 %>%
  mutate(time = "t_1")

t_2 <- t_2 %>%
  mutate(time = "t_2")

t_3 <- t_3 %>%
  mutate(time = "t_3")

t_4 <- t_4 %>%
  mutate(time = "t_4")

t_5 <- t_5 %>%
  mutate(time = "t_5")

#row_binding the three times
full <- bind_rows(t_1, t_2, t_3, t_4, t_5)
```

From there, the same cleaning techniques from Chapter 3 are employed. One final step is to join the tweets with a data frame of the game outcomes. 

```{r, eval = FALSE, size = "small"}
tweets_final <- tweets_final %>%
  left_join(outcomes, by = c("Team", "time"))
```

### Sentiment Analysis

Again, our functions and techniques from the previous study are employed with slight variations. From the last study, I found that certain words commonly used by football fans on Twitter are not included in the lexicon but are used as positive sentiments. The first step for sentiment analysis of this study is to add these words as rows to the end of the bing lexicon data frame. 

```{r, eval = FALSE, size = "small"}
#creating data frame with additional sentiments
extra<-data.frame(word = c("rings", "ring", "history", "clutch", 
                    "congrats", "dynasty", "goat", "g.o.a.t."), 
               sentiment = "positive")

#binding to bing lexicon
bing_lex <- get_sentiments("bing")

sent_full <- bind_rows(bing_lex, extra)
```

From there, the same loop run in the previous study could be used if we wanted the positive and negative word counts for each player across all five time points. However, for the purpose of our study, we wrote an altered function that determines the sentiments for each player at each time point. This was done by adding a time argument that filters the tweets for that time point. Also, within the function, the other variables of total sentiment, negative word percentage, positive word percentage, time, and player name are added to the counts data frame. 

```{r, eval = FALSE, size = "small"}
sent <- function(t){
  
#list of names
names <- as.list(subset2$name_clean)

#list of integers
index <- as.list(1:length(names))

#creating time object to filter df
time1 <- paste0("t_", t)

add_sentiments <- function(i) {
  
  #filter for each person and the correct time
  tweets <- tweets_final %>%
    filter(name_clean_final == names[i],
           time == time1)
  
  #one word per row
  words <- tweets %>% 
    select(ID, full_text_low) %>% 
    unnest_tokens(word,full_text_low)
  
  #creating df of stop words  
  my_stop_words <- stop_words %>% 
    select(-lexicon) %>% 
    bind_rows(data.frame(word = c("https", "t.co", "rt", 
                                  "amp","4yig9gzh5t","fyy2ceydhi",
                                  "78","fakenews")))

  #anti-join with stop words to filter those words out
  tweet_words <- words %>% 
    anti_join(my_stop_words)

  #joining sentiments with non-stop words from tweets
  fn_sentiment <- tweet_words %>% 
    left_join(sent_full) 
  
  #creating df with n of sentiments
  df <- fn_sentiment %>% 
    filter(!is.na(sentiment)) %>% 
    group_by(sentiment) %>% 
    summarise(n=n())

  #making df of sentiments for each person
  df_2 <- df %>%
  mutate(player = names[i]) %>%
  spread(key = sentiment, value = n)
  
  return(df_2)
  
}

#running add sentiment function for each player
sentiment_full <- map_df(index, add_sentiments)

#creating percentages
sentiment_full <- sentiment_full %>%
  mutate(totalsentiment = negative + positive,
         neg_perc = negative/totalsentiment * 100,
         pos_perc = positive/totalsentiment *100,
         time = paste0("t_", t),
         player = as.character(player))
  

return(sentiment_full)

}
```

This function is run 5 times to determine sentiments for each of the five time points. These are combined to create a data frame with 120 rows (24 players $\cdot$ 5 time points). Then, it is joined with the subset dataframe that contains 5 rows per player to include outcome per time point. 

```{r, eval = FALSE, size = "small"}
#sentiments for time 1
sent_tall_1 <- sent_tall(1)

#sentiment for time 2
sent_tall_2 <- sent_tall(2)

#sentiment for time 3
sent_tall_3 <- sent_tall(3)

#sentiment for time 4
sent_tall_4 <- sent_tall(4)

#sentiment for time 5
sent_tall_5 <- sent_tall(5)

#combining outcome to players
outcomes_players <- subset2 %>%
  full_join(outcomes, by = "Team")

#row_binding all of the sentiments together
sent_tall_full <- sent_tall_1 %>%
  bind_rows(sent_tall_2, sent_tall_3, sent_tall_4, sent_tall_5)

#joining sentiment tall to outcomes
sent_tall_full1 <- outcomes_players %>%
  left_join(sent_tall_full, by = c("name_clean" = "player", "time"))
```

The data frame created here is the final one to be used in our model. However, one additional variable is added to account for individual performance during a game. To gather game level data, we use the `nflscrapR` package in `R` [@nflscrapr]. First, we use the `scrape_game_ids()` function to gather the game ids for the first 6 weeks of the 2017 season. Then, we filter for only the teams included in our subset.

```{r, eval = FALSE, size = "small"}
#gathering game ids for first 6 weeks in 2017
week1_to_6 <- scrape_game_ids(2017, weeks = c(1, 2, 3, 4, 5, 6))

#specifying 8 teams from subset
teams <- c("CIN", "DAL", "SEA", "CAR", "TB", "PHI", "KC", "BAL")

#filtering dataset for only those 8 teams
week1_to_6_filt <- week1_to_6 %>%
  filter(home_team %in% teams | away_team %in% teams)
```

After that, 6 data frames are created that each contain the game ids for the corresponding week. Weeks 1 and 6 had additional filtering arguments to filter for the correct teams. From there, a column that includes the players first initial and last name is added to the subset data frame (from Table \@ref(tab:subset)). For each week, the game ids are added to a list. A function we wrote, `get_stats()`, gathers the stats for all players from the corresponding game using the `player_game()` function of the `nflscrapr` package. Then, we use the `map_df` function from the `purrr` package to run this function for each game of the week included in the list [@purrr]. Ultimately, this function combines the data frames from each game. Once the data frame containing all the stats for the games of that week is constructed, it is filtered for the players of our subset. The variable of yards per game is creating by combining the three columns of passing yards, rushing yards, and receiving yards. 

```{r, eval = FALSE, size = "small"}
##week 2
#game ids added to list
week2 <- as.list(week2$game_id)

#list of integers
index <- as.list(1:7)

#looping through game ids to get stats 
get_stats <- function(i) {
  
  df <- player_game(week2[i])
  
  return(df)
  
}

#stats for all 7 games
week2_stats <- map_df(index, get_stats)


#pulling out names
names_week2 <- subset2$name_2

#creating long string of all names
all_name2 <- paste(names_week2, collapse='|')

week2_stats <- week2_stats %>%
  #filtering for name matches
  mutate(match = ifelse(grepl(all_name2, name), 1, 0)) %>%
  #there is another R.Wilson but we only want the seahawks R.Wilson
  filter(match == 1, !(name == "R.Wilson" & Team == "KC")) %>%
  select(name, Team,  passyds, rushyds, recyds) %>%
  #creating full yards and time columns
  mutate(full_yards = passyds+ rushyds+ recyds,
         time = ifelse(Team %in% week_1, "t_2", "t_1")) %>%
  select(name, Team, full_yards, time)
```

This process is completed for each week. Then, the resulting data frames are combined and joined on the model data by name and time. One final adjustment is made to our yards variable in order to standardize yards for quarterbacks and receivers. As quarterbacks can gain yardage through multiple receivers but receivers can only gain yardage on their own, the yards are on two different scales. The common ratio of yards for quarterbacks to receivers is 3:1, with 300 and 100 yard games for quarterbacks and receivers, respectively, indicating successful games. To standardize, the number of total yards for quarterbacks is divided by 3. 

###Modeling

As stated earlier, the chosen modeling approach for this project is multi-level modeling. If a more simple modeling approach was used, we would not be accounting for the dependence in our data and the estimates of the coefficients' standard errors would be less accurate. The lowest level in our data contains the repeated observations for each player. The variable being measured at that level is the yards per game, which is a numeric variable greater than zero. The second level in our data is the player level. The variables being measured at that level are race, which is a factor variable with factors "W" and "B" for "white" and "black", and position, which is a factor variable with factors "R" and "QB" for "receiver" and "quarterback". The third level is the team level. The variable being measured at that level is the game outcome, which is a factor variable with factors "W" and "L" for "win" and "loss". Our goal with the model is to get main effects for those four variables and an additional main effect for the interaction term between race and outcome. The results of this model will best help us answer our research question and test our hypotheses. Below are the regression equations at each of the three levels then the final equation combining those three.

Level 1:
$~$

$negperc_{tij} = \beta_{0ij} + \beta_{1ij}totalyards_{tij} + \varepsilon_{tij}$

Level 2:
$~$

$\beta_{0ij} = \gamma_{00j} + \gamma_{01j}race_{ij} + \gamma_{02j}position_{ij} + u_{0ij}$

$\beta_{1ij} = \gamma_{10j}$

Level 3:
$~$

$\Upsilon_{00j} = \delta_{000} + \delta_{001}outcome_{j} + v_{0j}$ 

$\Upsilon_{01j} = \delta_{010} + \delta_{011}outcome_{j}$

$\Upsilon_{02j} = \delta_{020}$

$\Upsilon_{10j} = \delta_{100}$

First, we substitute the equations from level 2 into the equation from level 1:
$~$

\begin{align*}
negperc_{tij} = &(\gamma_{00j} + \gamma_{01j}race_{ij} + \gamma_{02j}position_{ij} + u_{0ij}) +\\
&(\gamma_{10j})totalyards_{tij} + \varepsilon_{tij}
\end{align*}
   
From there, we can substitute in the equations from level 3:
$~$

\begin{align*}
negperc_{tij} = &\delta_{000} + \delta_{001}outcome_{j} + v_{0j} + \\
&(\delta_{010} + \delta_{011}outcome_{j})race_{ij} + \\
&(\delta_{020})position_{ij} + u_{0ij} +\\
&(\delta_{100})totalyards_{tij} + \varepsilon_{tij}
\end{align*}


In final form, with all of the variables in the correct order, is written as:
$~$
\begin{align*}
negperc_{tij} = &\delta_{000} + \delta_{001}outcome_{j} + \delta_{010}race_{ij} \\
&+ \delta_{020}position_{ij} + \delta_{100}totalyards_{tij}\\
&+\delta_{011}outcome_{j}race_{ij} + v_{0j} + u_{0ij} + \varepsilon_{tij}
\end{align*}

The fixed effects of this model include $\delta_{000}$, $\delta_{001}$, $\delta_{010}$, $\delta_{020}$, $\delta_{100}$, and $\delta_{020}$. The third level random effects is $v_{0j}$ which accounts for the random variance of predicted intercepts (average percentage of negative words) between teams. The second level random effect is $u_{0ij}$, which accounts for random variance of predicted intercepts for players within teams. Finally, the first level random effect is $\varepsilon_{tij}$, which accounts for random variance of predicted intercepts for players within teams across the five time points. These random effects are assumed to have means at zero and be normally distributed:

$v_{0j} \sim N(0, \tau_{000})$

$u_{0ij} \sim N(0, \tau_{001})$

$\varepsilon_{tij} \sim N(0, \sigma_{\varepsilon}^2)$

This model keeps the effect of yards, position, race, and outcome fixed instead of allowing for variance across players or teams. These variables are being kept constant because we do not have prior knowledge that would lead us to believe the effects of these variable are different across certain players or teams. The three random variance terms are accounting for the variance in average percentage of negative words across time points, players, and teams. 

There are multiple reasons why we chose to use multilevel regression modeling instead of regular linear regression modeling. The main reason we chose this technique is because of the hierarchical nature of our data. If we did not account for the random variance at each level, we would be treating each observation as independent when they are not. As a result, the standard errors will be underestimated and significance will be overstated. The standard errors for coefficients of higher-level predictor variables will be most affected. This could lead to more Type I errors.

A common method to estimate coefficients in multilevel regression is the maximum likelihood method. This is a general estimation procedure, which creates estimates of the population parameters that maximize the probability (maximum likelihood) of observing the data that are actually observed, given the model. The benefit of this estimation method is that it is generally robust, and produces estimates that are asymptotically efficient and consistent. However, in this study, our regression coefficients are estimated using a slightly altered method, known as REML (restricted maximum likelihood). During estimation using this method, only the variance components are a part of the likelihood function, and the coefficients are estimated in a second estimation step. This produces parameter estimates with associated standard errors as well as an overall deviance, which is a function of the likelihood [@hox2010multilevel]. The reason for using REML instead of the standard ML is due to our small sample size of 120 observations. The REML method estimates the random effects after removing the fixed effects of the model. Unlike other methods, which do not account for the degrees of freedom lost by estimating fixed effects, REML produces estimates that are less biased in smaller sample sizes.

To fit the above model in `R`, the `lme4` package is used [@lme4]. The function used is `lmer()`, which in our case, takes two arguments: the formula and the data. Within the formula, we specify our fixed and random effects. The code used is below. 

```{r, eval = FALSE, size = "small"}
model <- lmer(neg_perc ~ outcome * Race + position + yards_fixed
              + (1|name_2) + (1|Team.x),
              data = data2)
```

##Results

###Summary Statistics
```{r, include = FALSE}
full_stats <- read.csv("/Users/juliannaalvord/Documents/nfl sentiment/final_data/full_stats.csv")

model_data <- read.csv("/Users/juliannaalvord/Documents/nfl sentiment/final_data/use_for_model1.csv", stringsAsFactors = F)

qb <- c("alex smith", "jameis winston", "joe flacco", "carson wentz", "cam newton", 
        "dak prescott", "russell wilson", "andy dalton")

#adding in position
model_data <- model_data %>%
  mutate(position = ifelse(name_clean %in% qb, "qb", "r"))

model_data <- model_data %>%
  separate(Name, c("first", "last"), " ") %>%
  mutate(first_init = substr(first, 1, 1),
         last = ifelse(last == "Jeffrey", "Jeffery", last),
         name_2 = paste(first_init, last, sep = ".")) %>%
  left_join(full_stats, by = c("name_2" = "name", "time" = "time"))

#filtering missing sentiments
data2 <- model_data %>%
  filter(!is.na(neg_perc)) %>%
  mutate(win_bin = ifelse(outcome == "W", 1, 0),
         lose_bin = ifelse(outcome == "L", 1, 0),
         black_bin = ifelse(Race == "B", 1, 0))


data2 <- data2 %>%
  mutate(yards_fixed = ifelse(position == "qb", full_yards/3, full_yards))

#write.csv(data2, "/Users/juliannaalvord/Documents/nfl sentiment/final_data/mlm_data.csv", row.names = FALSE)
```

The mean percentage of negative words across all time points and players is `r round(mean(data2$neg_perc), 1)`%. This variable is fairly normally distributed, with a slight left skew, as shown in Figure \@ref(fig:dist).

```{r dist, echo = FALSE, fig.cap="Histogram of Response Variable"}
ggplot(data2, aes(neg_perc)) + geom_histogram(bins = 10) +
  theme_classic()+
  theme(axis.title.y = element_blank()) +
  xlab("Percentage of Negative Words")
```

Next, we hoped to determine the mean percentage of negative words when breaking down by race and outcome, our two main variables of focus. As shown in Figure \@ref(fig:bargraph), the median percentage of negative words for a win is 46.2% for black players and 46.89% for white players. For a loss, the mean percentage of negative words is 65.17% for black players and 58.96%. 

```{r, include=FALSE}
sent_tall_full1 <- read.csv("/Users/juliannaalvord/Documents/nfl sentiment/final_data/use_for_model1.csv", stringsAsFactors = F)
```

```{r, include = FALSE, fig.cap="Mean Percentage of Negative Words across Race and Outcome"}
sent_tall_full1$outcome1 <- factor(sent_tall_full1$outcome, labels = c("Lost", "Won"))

#gathering by race, player and sentiment
subset_sent_format <- sent_tall_full1 %>%
  dplyr::select(name_clean, Race, outcome1, 21:22) %>%
  gather(sentiment, n, 4:5)

#grouping by sentiment and race then making mean for each sentiment/race
subset_sent_2 <- subset_sent_format %>%
  dplyr::group_by(sentiment, Race, outcome1) %>%
  summarise(mean_perc_sent = mean(n, na.rm = T))

subset_sent_2 <- subset_sent_2 %>%
  filter(sentiment == "neg_perc")
```

```{r bargraph, echo = FALSE, warning=FALSE, message=FALSE, fig.cap="Mean Percentage of Negative Words across Race and Outcome"}
#same viz but by outcome as well
ggplot(subset_sent_2, aes(x = sentiment, y = mean_perc_sent, fill = Race)) +
  geom_bar(stat = "identity", position = "dodge", color = "black") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_fill_manual(values=c("black", "white")) + facet_wrap(~outcome1) +
  theme_bw() +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank()) +
  xlab("Percentage of Negative Words") +
  ylab("Average Percentage of Total Sentiment") +
  geom_text(
    aes(label = round(mean_perc_sent, digits = 2), y = mean_perc_sent + 1),
    position = position_dodge(0.9),
    vjust = 0
  )
```

### Missing Data
Tweets in this study are gathered at five different time points for the 24 players. This results in a final $n$ of 120 observations. However, 6 of these 120 are missing due to a lack of tweets or sentiment words.

###Multi-level Model

Below is Table \@ref(tab:tab1) with the results of our model. 
```{r, message=FALSE, warning=FALSE, include = FALSE}
mlm_model <- lmer(neg_perc ~ outcome * Race + position + yards_fixed
              + (1|name_2) + (1|Team.x),
              data = data2)
#summary(mlm_model)
#confint(mlm_model)
```

----------------------------------------------------------------------------------------
  Variable                  Estimation      St.Error        p-Value         95% CI
------------------------- -------------- -------------- -------------- -----------------
  Intercept                    74.21          4.85           0.00        [64.92, 83.42]
  
  OutcomeW                    -19.08          3.12           0.00       [-25.19, -13.01]  
  
  RaceW                        -7.22          3.90           0.08        [-14.66, 0.21] 
  
  PositionR                    -4.11          3.24           0.22        [-10.37, 2.14]
  
  Fixed Yards                  -0.09          0.04           0.02        [-0.16, -0.01]
  
  OutcomeW:RaceW                6.72          4.59           0.15        [-2.06, 15.82]
------------------------- -------------- -------------- -------------- -----------------
Table: (\#tab:tab1) Estimates of $\delta$ coefficients from our multilevel regression model

The resulting formula with the $\delta$ coefficients included is as follows:

\begin{align*}
{negperc} = &74.21 - 19.08\widehat{OutcomeW} - 7.22\widehat{RaceW} - 4.11\widehat{PositionR}\\
& - 0.09\widehat{Yards} + 6.74\widehat{OutcomeW*RaceW}
\end{align*}

The intercept ($\delta_{000}$) of 74.21 means that the average percentage of negative words for black players with 0 yards during a loss is 74.21%. We are 95% confident that the true value of the intercept is between 64.92% and 83.42%. The $\delta_{001}$ coefficient estimate of -19.08 means that on average, the percentage of negative words for black players is 19.08 percentage points lower during a win for the same position and yardage. We are 95% confident that the true value of this coefficient is between -25.19% and -13.01%. In this case, The $\delta_{010}$ coefficient estimate of -7.22 means that on average, the percentage of negative words during a loss decreases by 7.22% for white players relative to black players for the same position and yardage. We are 95% confident that the true value of this coefficient is between -14.66% and 0.21%. The $\delta_{020}$ coefficient estimate of -4.11 means that on average, the percentage of negative words during a loss for black players decreases by 4.11% for receivers, holding yards constant. We are 95% confident that the true value of this coefficient is between -10.37% and 2.14%. The $\delta_{100}$ coefficient estimate of -0.09 means that on average, for each 1 additional yard gained by a receiver (3 yards for a quarterback), the percentage of negative words for black players during a win decreases by 0.09%, holding position constant. We are 95% confident that the true value of this coefficient is between -0.16% and -0.01%. The coefficient estimate of 6.72 for the interaction between race and outcome means that during a win, the percentage of negative words for white players increases by 6.72%, holding position and yards constant. We are 95% confident that the true value of this coefficient is between -2.06% and 15.82%.

The coefficient estimates of two of our variables are considered statistically significant at the p < 0.05 mark. They are the outcome and total yards variable. Based on our hypothesis, we expected race to be a significant predictor of the percentage of negative words. The p-value for the coefficient estimate of this variable is 0.08 which technically falls above the significance cutoff. However, the difference between 0.08 and the significant cutoff of 0.05 is small. We have purposefully avoided language of statistical significance when describing the coefficient estimates as the designation of certain estimates as "significant" and "not significant" leads some to be considered "worthy" while others are not [@wasserstein2016asa]. Despite our race variable not reaching the arbitrary significant cutoff, we do not deem the estimate to be unworthy. The importance of the effect size of this variable cannot be understated, no matter the p-value. Take the example of Christian McCaffrey, who is perceived to be white, vs. Devin Funchess, who is perceived to be black, both of whom are receivers for the Carolina Panthers. If we compare the results of our model for these two players during a game that is lost where they each total 100 yards, the estimates are: 

__For Christian McCaffrey:__

\begin{align*}
{negperc} = &74.21 - 19.08(0) - 7.22(1) - 4.11(1) - 0.09(100) + 6.74(0)
\end{align*}

\begin{align*}
{negperc} = 54%
\end{align*}

__For Devin Funchess:__

\begin{align*}
{negperc} = &74.21 - 19.08(0) - 7.22(0) - 4.11(1) - 0.09(100) + 6.74(0)
\end{align*}

\begin{align*}
{negperc} = 61%
\end{align*}

Despite an identical performance, these two players have vastly different amounts of negative sentiment with the only distinguishing feature between them being their race. To further put these results into perspective, the difference in negative words percentage between white and black players during a game that was lost is equal to a difference of approximately 80 yards for receivers and 240 yards for quarterbacks. In other words, Devin Funchess would need to gain 80 more yards than Christian McCaffrey during a game that was lost in order to have the same observed percentage of negative words.

### Assumptions

The assumptions for multilevel linear regression are the same as for simple linear regression. Below, we check the four assumptions of linearity, normality, homoscedasticity, and independece. 

#### Linearity

The assumption states that there must be a linear relationship between the explanatory and response variables. This is only applicable for the relationship between total yards and percentage of negative words as the other explanatory variables are binary.

```{r linearity, message=FALSE, warning=FALSE, echo = FALSE, fig.cap="Plot of Yards and Percentage of Negative Words for Linearity Assumption"}
ggplot(data2, aes(yards_fixed, neg_perc)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  xlab("Total Yards (standardized)") +
  ylab("Percentage of Negative Words") +
  theme_classic()
```

As seen from figure \@ref(fig:linearity), there does appear to be a negative linear relationship between total yards and percentage of negative words. Therefore, the linearity assumption is not violated.

#### Normality

The normality assumption states that residuals must be normally distributed at all levels.

```{r normal1, message=FALSE, message=FALSE, echo=FALSE, fig.cap="Plot of Residual Normality at the First Level in our Data"}
model3 <- lme(neg_perc ~ outcome * Race + position + yards_fixed,
               random = ~ 1 | Team.x/name_2, data = data2)

qqnorm(model3)
```

Figure \@ref(fig:normal1) plots the standardized residuals against the quantiles of standard normal at the first level. It appears that our residuals are fairly normally distributed. 

```{r normal2, message=FALSE, warning=FALSE, echo=FALSE, fig.cap="Plot of Residual Normality at the Second Level in our Data"}
qqnorm(model3, ~ranef(., level=2))
```

Figure \@ref(fig:normal2) plots normality of our residuals at the player level. Like figure \@ref(fig:normal1), it appears that our residuals are fairly normally distributed at this level. 

```{r normal3, message=FALSE, warning=FALSE, echo=FALSE, fig.cap="Plot of Residual Normality at the Third Level in our Data"}
qqnorm(model3, ~ranef(., level=1))
```

The normality of residuals from the team level is displayed in Figure \@ref(fig:normal3). These residuals appear less normally distributed than the residuals of the prior levels. However, it is harder to determine with so few residuals and even so, there does not appear to be enough evidence to conclude that our residuals are not normally distributed at this level. 

#### Homoscedasticity

This assumption states that variances of the residuals must be equal across groups.

```{r homosc, message=FALSE, warning=FALSE, echo=FALSE, fig.cap="Fitted vs. Residual Plot"}
plot(mlm_model, xlab = "Fitted Value", ylab = "Residual")
```

From Figure \@ref(fig:homosc), there do not appear to be any patterns or trends in the distribution of the residuals which indicates an equal variance. 

#### Independence

Linear regression assumes that all cases in a sample are independent from one another. In our case, this would mean that knowing the negative sentiment of one player at one time point would not help us predict the negative sentiment of that same player at another time point or another player entirely. This is not true and is the main reason why multilevel modeling is necessary. In multilevel modeling, we do additionally assume that level 1, 2, and 3 residuals are uncorrelated (independent).


### ICC

The intraclass correlation (ICC) in multilevel modeling indicates the proportion of the variance explained by the clustered structure and is measured by dividing the variance for that level over the total variance. These calculations are done using the variances from the null model:

\begin{align*}
negperc_{tij} = \delta_{000} + V_{0j} + &U_{0ij} + \varepsilon_{tij}
\end{align*}

ICC calculation at the team level:

$~$

$ICC_{V_j} = \sigma_{V_j}^2/(\sigma_{V_j}^2+\sigma_{U_{ij}}^2+\sigma_{\epsilon_{tij}}^2)$

```{r, include =FALSE, eval = FALSE}
model_null <- lmer(neg_perc ~ 1
              + (1|name_2) + (1|Team.x),
              data = data2,
              na.action = na.omit)

summary(model_null)

#player level
1.649/(1.649+12.713+218.964)
#team level
12.713/(1.649+12.713+218.964)
```

ICC calculation at the player level:

$~$

$ICC_{U_{ij}} = \sigma_{U_{ij}}^2/(\sigma_{V_j}^2+\sigma_{U_{ij}}^2+\sigma_{\epsilon_{tij}}^2)$

$~$

For our model, the ICC is 0.05 for level 3 (team level) and 0.007 for level 2 (player level). These numbers inform us that we have very little team variance and even less player variance. So, generally, this means that there is little evidence that football fans on Twitter feel more or less negatively about certain teams or certain players. The extremely small value at the player level may indicate that adding the random effect for players to our model is not neccesary. However, when running our 3 level model, we realize that instead of decreasing, the ICC at the player level increases to 0.12. We expect that when adding predictors, more of the random variance at the player and team levels would be explained by the model. While this is the case at the team level, it is not at the player level. 

We expect there to be random variance between players due to some players being naturally liked more compared to others. Therefore, we were surpised that our ICC calculated from the null model is so small. To investigate this small ICC that increases when adding predictors, we first determined which variable was causing the largest increase in player level random variance. We found that this variable is game outcomes. This suggests that the players with naturally higher percentages of negative tweets are also on losing teams whereas the players with naturally lower percentages of negative tweets are also on winning teams. Essentially, by not looking at differences in outcome, the natural variance between players is being masked. 

After coming to this conclusion, we decided that there is sufficient evidence that we cannot treat our observations as independent. This confirms that using multilevel regression to account for the random variances at the three levels is necessary. 

### Sensitivity Analysis

Based on a number of factors discussed above, we decided upon the three-level multilevel model. The next sections investigate the amount that our standard errors and p-values change depending on the modeling method. 

#### Two-level Model

Had we not further investigated the low ICC at the player level from our null model, we may have decided to run a two-level multilevel model that does not account for the random variance at the player level. In this case, the results are as follows:

```{r, message=FALSE, warning=FALSE, include=FALSE}
mlm_model2 <- lmer(neg_perc ~ outcome * Race + position + yards_fixed
              + (1|Team.x),
              data = data2)
#summary(mlm_model2)
#confint(mlm_model2)
```
----------------------------------------------------------------------------------------
  Variable                  Estimation      St.Error        p-Value         95% CI
------------------------- -------------- -------------- -------------- -----------------
  Intercept                    74.21          4.71           0.00        [65.13, 83.23]
  
  OutcomeW                    -19.37          3.23           0.00       [-25.57, -13.08]  
  
  RaceW                        -7.35          3.54           0.04        [-14.18, -0.50] 
  
  PositionR                    -3.90          2.66           0.15        [-9.02, 1.28]
  
  Fixed Yards                  -0.09          0.04           0.02        [-0.16, -0.01]
  
  OutcomeW:RaceW                7.42          4.68           0.12        [-1.63, 16.46]
------------------------- -------------- -------------- -------------- -----------------
Table: (\#tab:tab2) Estimates of $\delta$ coefficients from a two-level multilevel regression model

Compared to the p-values from table \@ref(tab:tab1), those from \@ref(tab:tab2) are all smaller. 

#### Linear Regression Model

Another method to model this data would be linear regression that is not heirarchical. The results of this model do not pick up any of the random variance at the player or team levels of our data.

```{r, echo = FALSE, include = FALSE}
model_lm <- lm(neg_perc ~ outcome * Race + position + yards_fixed, data = data2)

#summary(model_lm)
#confint(model_lm)
```

----------------------------------------------------------------------------------
  Variable                  Estimation      St.Error        p-Value         95% CI
------------------------- -------------- -------------- -------------- -----------------
  Intercept                    73.37          4.57           0.00       [64.31, 82.43]
  
  OutcomeW                    -18.92          3.33           0.00       [-25.51, -12.31]
  
  RaceW                        -7.26          3.66           0.05       [-14.51, -0.01]
  
  PositionR                    -3.67          2.76           0.19        [-9.15, 1.81]
  
  Fixed Yards                  -0.08          0.04           0.04       [-0.16, -0.004]
  
  OutcomeW:RaceW                7.33          4.87           0.13       [-2.33, 16.99]
------------------------- --------------- -------------- -------------- -----------------
Table: (\#tab:tab3) Estimates of $\beta$ coefficients from a basic linear regression model

Once again, there are differences between Table \@ref(tab:tab3) and Table \@ref(tab:tab1) in terms of coefficients, standard errors, and p-values. While the results of either of the previous two models may appear more preferable given society's focus on statistical significance, these models are commiting Type I errors by under-estimating the standard errors of the coefficients.  

##Discussion

To begin, our results suggest that there is a strong relationship between outcome and percentage of negative words. The negative direction of this coefficient, meaning that a win results in a lower percentage of negative words, assured us that our data is reliable. If the percentage of negative words increased during a win, we would be suspicious that our data is not credible. This direction informs us that during a positive outcome, the percentage of negative words towards players decreases. This confirms our first hypothesis. The direction of the other performance variable, total yards, also suggests that better performance leads to a lower percentage of negative words, another indication of reliable data.

The main research question for this project mainly involved differences between white and black players. To reiterate, our research question is: Are sentiments on Twitter more negative towards black NFL players after controlling for game outcome, position, and quality of play? We also hypothesize that during a game that was lost, sentiments would be more negative toward black players. The negative direction of the race coefficient confirms this hypothesis. The coefficient estimate indicates that during a loss, sentiments are more negative towards black players. However, our interaction variable suggests that this difference is much smaller during a game that is won. For a white player during a win, the percentage of a negative words is only 0.5% (-7.22% + 6.72%) lower compared to black players.

While our model's coefficient estimate for position is negative, meaning that receivers receive fewer negative sentiments on average than quarterbacks, this effect size is not as strong. We did not expect there to be differences between the two positions but included this variable in order to control for position while investigating the relationship between race, outcome, and percentage of negative words.

Our results are consistent with other studies that found that language for black and white football players is unequal, with black players receiving more negative sentiments than white players, especially during a loss. This disparity is evidence of Twitter-using football fan's racial bias, a phenomenon rarely studied without survey data. Unlike other research, this study uses data on a much larger scale to quantify previous findings. As stated in Chapter 1, @hylton2016your argue that further research involving more subtle forms of racism and racial discrimination in sports is necessary. Through this study, one of our main goals is to shed light on a subtle form of racism which takes form through racially disproportionate negative language.

###Limitations and Future Directions

These results should be considered in light of their limitations. First, some players are missing data at certain time points. This means that no positive or negative words were included in the tweets for those players at that time point. This lowered our already small sample size which can have an affect on the validity of our results. The small sample size was partially due to the Twitter API limits. In order to gather enough tweets to find positive and negative words, we could not have realistically added more time points. If we were able to gather more than 250,000 tweets, we could have added more time points while still gathering enough tweets for sentiment analyses. This would have increased our sample size and made our estimates more accurate. By doing so, important relationships may have been revealed.

Additionally, this study only gathers tweets for 24 players, which is a small subset of the entire NFL roster of quarterbacks and receivers. With more players added to the study, our results may be more generalizable. In the future, it would be beneficial to gain greater access to Twitter's API search. Unfortunately, this would require a larger monetary contribution which was not possible in the current study. Luckily, as seen from Study 1, there are other methods of accessing the API which are free. With enough planning, tweets could be gathered using the streaming method during the games of the upcoming season. This would both increase the subset of players and number of total tweets. 

Another limitation to this study is that the race of the players is based on our perception and could be unreliable. In the future, having multiple people offering their perceptions of the players' races could improve results and reduce biases. In addition to the race variable, adding more demographic data about the players or extra variables of individual performance could better disseminate the relationship of interest from our research question.

Nevertheless, these limitations are offset by strengths. The balanced nature of this study allowed us to get closer to making causal claims of racial impacts on the percentage of negative words. Furthermore, though it would have been favorable to gather more tweets, this study used more data than many previous studies and therefore offers previously untapped quantitative insights. 

